[
  {
    "objectID": "next-steps.html",
    "href": "next-steps.html",
    "title": "Next Steps",
    "section": "",
    "text": "Congratulations on completing the practical! Here are some useful resources.",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#stack-overflow-forums",
    "href": "next-steps.html#stack-overflow-forums",
    "title": "Next Steps",
    "section": "Stack Overflow & Forums",
    "text": "Stack Overflow & Forums\nThese communities are invaluable:\n\nStack Overflow - Programming Q&A\nRStudio Community - R-specific help",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#for-r",
    "href": "next-steps.html#for-r",
    "title": "Next Steps",
    "section": "For R",
    "text": "For R\n\nR for Data Science (2e) - Comprehensive free book by Hadley Wickham\nRStudio Primers - Interactive tutorials\nSwirl - Learn R programming interactively",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#for-python",
    "href": "next-steps.html#for-python",
    "title": "Next Steps",
    "section": "For Python",
    "text": "For Python\n\nPython for Everybody - Free course by University of Michigan\nKaggle Learn - Practical micro-courses\nDataCamp - First course free, student discounts available\n\nStatistics with R/Python:\n\nStatQuest - Excellent YouTube channel for statistics\nIntroduction to Statistical Learning - Free book with R and Python code",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#build-your-portfolio",
    "href": "next-steps.html#build-your-portfolio",
    "title": "Next Steps",
    "section": "Build Your Portfolio",
    "text": "Build Your Portfolio\n\nProject Ideas\n\nAnalyze local transport patterns using open transport data\nRecreate published analyses to learn techniques\nContribute to open source R or Python packages\n\n\n\nShare Your Work\n\nCreate a GitHub profile for your code\nBuild a portfolio website with Quarto\nWrite blog posts about what you learn\nShare projects on social media (#RStats, #DataScience)",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#advanced-topics-to-explore",
    "href": "next-steps.html#advanced-topics-to-explore",
    "title": "Next Steps",
    "section": "Advanced Topics to Explore",
    "text": "Advanced Topics to Explore\nOnce you’re comfortable with basics:\n\nData Science Skills\n\nVersion Control: Git and GitHub for collaboration\nReproducible Research: R Markdown, Quarto, Jupyter notebooks\n\n\n\nSpecialized Topics\n\nSpatial Data Science: Working with spatial data (check out geocompx.org)\nMachine Learning: Supervised and unsupervised learning\nDeep Learning: Neural networks for complex patterns\nTime Series Analysis: For temporal data\nNetwork Analysis: For transport networks and relationships",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "next-steps.html#final-tips",
    "href": "next-steps.html#final-tips",
    "title": "Next Steps",
    "section": "Final Tips",
    "text": "Final Tips\n\n\n\n\n\n\nTipThe Best Way to Learn\n\n\n\nPractice, practice, practice! Learning data science is like learning a language—you need to use it regularly to improve.\n\n\n\n\n\n\n\n\nImportantDon’t Get Overwhelmed\n\n\n\nThere’s a lot to learn, but you don’t need to learn everything at once. Pick one area, get comfortable, then expand gradually.\n\n\n\n\n\n\n\n\nNoteStay Curious\n\n\n\nThe field of data science is constantly evolving. Stay curious, keep learning, and don’t be afraid to experiment!",
    "crumbs": [
      "Next Steps"
    ]
  },
  {
    "objectID": "collaboration.html",
    "href": "collaboration.html",
    "title": "Collaboration with Git & GitHub",
    "section": "",
    "text": "Data science is rarely a solo endeavour. As you work on more complex projects, you’ll need to collaborate with others and keep track of changes to your code. This is where version control comes in.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#what-is-version-control",
    "href": "collaboration.html#what-is-version-control",
    "title": "Collaboration with Git & GitHub",
    "section": "What is Version Control?",
    "text": "What is Version Control?\nVersion control systems allow you to track changes to your files over time. They are like “save points” in a video game, allowing you to:\n\nRevert to previous versions of your code if something breaks.\nCompare changes over time to understand what happened.\nCollaborate with others without overwriting each other’s work.\n\nGit is the most popular version control system in the world.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#github",
    "href": "collaboration.html#github",
    "title": "Collaboration with Git & GitHub",
    "section": "GitHub",
    "text": "GitHub\nWhile Git runs locally on your computer, GitHub is a cloud platform for hosting and sharing Git repositories.\n\n“GitHub is like Facebook but for people who want to do useful things and share code!”\n\nIt acts as a central hub where you can store your projects, share them with the world, and collaborate with others.\n\nKey Concepts\n\nRepository (Repo): A project folder tracked by Git.\nCommit: A snapshot of your code at a specific point in time.\nPush: Sending your local commits to GitHub.\nPull: Downloading the latest changes from GitHub to your computer.\nBranch: A parallel version of your code where you can work on new features safely.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#collaboration-features",
    "href": "collaboration.html#collaboration-features",
    "title": "Collaboration with Git & GitHub",
    "section": "Collaboration Features",
    "text": "Collaboration Features\nGitHub isn’t just for storing code; it provides powerful tools for teamwork:\n\nIssues: Track bugs, tasks, and feature requests.\nPull Requests (PRs): Propose changes to a repository and request a review from teammates before merging them.\nDiscussions: Ask questions and share ideas with the community.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#getting-started",
    "href": "collaboration.html#getting-started",
    "title": "Collaboration with Git & GitHub",
    "section": "Getting Started",
    "text": "Getting Started\nTo start using Git and GitHub, we recommend installing GitHub Desktop or using the Git integration within RStudio or VS Code.\nFor an ideal next step in your learning journey, check out the courses available at GitHub Skills.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#deep-dive-into-github",
    "href": "collaboration.html#deep-dive-into-github",
    "title": "Collaboration with Git & GitHub",
    "section": "Deep Dive into GitHub",
    "text": "Deep Dive into GitHub\nThe following section provides a detailed look at using GitHub, including using the command line interface (gh), creating repositories, and understanding workflows in depth.\nNote: This content and the associated exercises are bonus material and are not expected to be completed during the 3-hour session. We recommend reading the “Introduction to GitHub” course on GitHub Skills before attempting the exercises in this area.\n\n\nClick here to expand the Advanced GitHub Material\n\n\nThere are significant advantages to using GitHub via the command line interface (CLI), known as gh. However, we acknowledge that interacting with a computer via the command line can take time to get used to. This learning curve is similar to the shift you might be experiencing moving from Excel-based workflows to code-based data science workflows. Both require a shift in mindset but offer powerful rewards in terms of reproducibility and efficiency.\n\nIntroduction to Version control\n\nGit\nWorking with code/scripts/notebooks usually involves preparing them, revising and editing their content, and sharing with others. After completing at least one round of this process you can end up with several different versions of the same file. Are you familiar with Figure 1?\n\n\n\n\n\n\nFigure 1: Version control. From: programmerhumor.io\n\n\n\nGit is a great tool that tracks changes to files over time, especially in text-based files such as scripts, allowing multiple people to work on the same project without overwriting each other’s work. When Git is used as a version control system, a full copy of the entire project history is stored, making it easy to keep track of any changes, and even revert any changes. By using Git, it is possible to have different alternative versions of the same project, i.e. repository, without the need for independent files or folders for each version.\n\n\n\nGit Workflow. From: Git for Data Science by Juha Kiili\n\n\n\n\nGitHub\nGitHub is a platform that provides hosting for Git repositories. As a cloud-based service GitHub works as a Hub for storing, sharing and collaborating with others. Some tools in GitHub, like pull requests for proposing changes, reviews for asking others to check your work, and issue tracking for monitoring things to be corrected or improved, ease the collaborative work in different projects. Other features (GitHub Actions) allow the automation of different processes, for example, building a web, and testing and deploying code.\nTo learn more about the different elements in GitHub, you can start exploring the GitHub skills courses.\n\n\nWorking with GitHub\nAny Data Science project will benefit from having a clear file structure. The starting point will be a folder (a.k.a. repository) in which we will store the code, data and other relevant files. We are going to use both Git and GitHub for keeping track of all changes.\nYou might already be familiar with some key terms in a typical Git workflow: clone, commit, push, pull, or branch. Here is a useful cheat sheet.\nThere are two main ways of working with GitHub repositories in your machine: the gh command-line tool from the shell and the GitHub desktop graphical user interface. It is also possible to use the built-in IDEs’ extensions, but they generally have fewer features available. We will explore the different actions in the next session.\n\n\nNavigating GitHub\n\nUsing the gh command line interface (CLI)\nYou can search repos, commits, issues, pull requests, and code with the gh CLI tool. For example, to search for repositories related to “transport” sorted by the number of stars, you can run:\ngh search repos --topic transport --sort stars --limit 5\nThat outputs the following:\nShowing 5 of 1081 repositories\n\nNAME                    DESCRIPTION                                                                                   VISIBILITY  UPDATED             \ngboeing/osmnx           Download, model, analyze, and visualize street networks and other geospatial features fro...  public      about 10 hours ago\neclipse-sumo/sumo       Eclipse SUMO is an open source, highly portable, microscopic and continuous traffic simul...  public      about 19 minutes ago\nHaivision/srt           Secure, Reliable, Transport                                                                   public      about 6 hours ago\nenisdenjo/graphql-ws    Coherent, zero-dependency, lazy, simple, GraphQL over WebSocket Protocol compliant server...  public      about 6 hours ago\ngboeing/osmnx-examples  Gallery of OSMnx tutorials, usage examples, and feature demonstrations.                       public      about 16 hours ago\nYou can search for repos related to transport data science with the following and similar commands, as shown in Figure 2.\ngh search repos \"transport data science\" --sort stars --limit 5\n\n\n\n\n\n\nFigure 2: Search results for transport data science repositories on GitHub using the gh CLI\n\n\n\nSee the gh CLI manual for more details.\n\n\nExploring GitHub’s web interface\nAfter you have logged into github.com, you can use the web application to explore open source software. You can search for people’s profiles and repositories (the public ones) using the search bar. Try looking for a topic, package, or researcher/developer whose work interests you.\n\n\n\n\n\nWhen you access any public repository, you will typically see the same information in a similar layout:\n\n\n\n\n\n\nFigure 3\n\n\n\nGitHub organizes a repository’s content and collaboration tools into several key tabs. These tabs act as a dashboard, each providing a different view of the project’s status and activity.\n\n\nThe Main Tabs\n\nCode: This is the repository’s home page. It displays the project’s file and folder structure as it currently exists on the main branch. You can browse and view all the code, read the README file, and see the latest commits, providing a snapshot of the project’s current state.\nIssues: This tab is a central hub for tracking tasks, bugs, and feature requests. It’s a key collaboration tool where developers can open new issues to report problems, ask questions, or propose new ideas. The discussion around an issue is contained in a single thread, keeping conversations organized and searchable.\nPull requests: When a contributor wants to merge their changes from one branch into another, they create a pull request. This tab lists all open, closed, and merged pull requests. Pull requests are where code review happens; collaborators can discuss the proposed changes, add comments, and approve the code before it is integrated into the main project.\nDiscussions: This tab is a more free-form space for conversations that are not tied to a specific bug or feature. It is a place for general questions, project announcements, or sharing ideas with the community. Think of it as a forum built right into the repository, allowing for broader, non-code-related conversations.\n\n\n\n\nCreating and managing repositories\nYou can create a repository from scratch or using an existing folder. The following instructions show the basic process for creating a new repository, which will create a Git repository on your machine and upload it to GitHub.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the gh command line interface (CLI) or a graphical user interface (GUI) like GitHub Desktop to create and manage repositories.\nWhile both approaches work, we recommend using the gh CLI because, after you have learned the commands, it is faster, more flexible, and easier to automate repetitive tasks.\nIf you want to create a repository using an existing folder, make sure to navigate to that folder in your terminal before running the gh repo create command.\n\n\n\ngh CLIGitHub Desktop\n\n\nTo create a repository from scratch, go to the location where you want to create your project using the shell, then run gh repo create to access the interactive mode.\nWe will select the first option:\n? What would you like to do?  [Use arrows to move, type to filter] \n&gt; Create a new repository on github.com from scratch\n  Create a new repository on github.com from a template repository\n  Push an existing local repository to github.com\nAssign a name. Remember that this will create a new folder with that name. We will call it myrepository.\n? Repository name\nNow select the owner of the repository, in this case, your username on GitHub.\n? Repository owner  [Use arrows to move, type to filter]\n&gt; yourGHname\nYou can provide a description for the repository. This can be edited afterwards.\n? Repository owner yourGHname\n? Description\nYou can choose whether your repository will be private or public. This can also be edited afterwards.\n? Visibility  [Use arrows to move, type to filter]\n&gt; Public\n  Private\nThe next steps will ask if you want to add README, .gitignore, and license files to your repository. A README file typically explains what the project is, why it is useful, and how others can get started using or contributing to it. A .gitignore file is a plain text file that tells Git which files or directories to intentionally ignore and not track. This is crucial for keeping a repository clean and secure. There are readily available templates based on programming languages; you can pick R in this case. Finally, the license file, if created, clearly states the legal terms under which the project’s code is distributed.\nAfter all questions, the interactive assistant will confirm if you want to create the repository.\n? Would you like to add a README file? Yes\n? Would you like to add a .gitignore? Yes\n? Choose a .gitignore template R\n? Would you like to add a license? Yes\n? Choose a license GNU Affero General Public License v3.0\n? This will create \"myrepository\" as a public repository on github.com. Continue? (Y/n) \nConfirm your repository and explore its contents!\n\n\nOpen the GitHub Desktop app. Click on the File menu and select New repository...\n\nA window asking for the details of your repository will appear.\n\nA .gitignore file is a plain text file that tells Git which files or directories to intentionally ignore and not track. This is crucial for keeping a repository clean and secure. There are readily available templates based on programming languages; you can pick R in this case. Finally, the license file, if created, clearly states the legal terms under which the project’s code is distributed.\nThis process will create the repository locally. In order to publish it on GitHub, you have to click on Publish repository.\n\n\n\n\nOnce your repository is created, you should be able to see it online. To access it, click on the Repositories tab in your profile page and select the repository you just created. You can see a list of repositories in your profile page by clicking on the Repositories tab, or typing github.com/username?tab=repositories in your browser, replacing username with your GitHub username. To see robinlovelace’s repositories, for example, you can type the following into your browser: github.com/Robinlovelace?tab=repositories.\n\n\nIf you want to create a repository from an existing project, you will need to initialize your repository. For this, go to the folder where you have your project with cd &lt;folder path&gt;, and run git init. This will create a local repository.\n\n\n\n\n\n\nImportant\n\n\n\nTo be able to use git in the command line, you need to have installed it from here\n\n\n\n\nCloning and Forking repositories\nTo work on a project from GitHub, you first need to create a local copy of the project/repository in your machine. This is referred as cloning the repository. Cloning creates an identical copy of the project, with all the files and their history. If you want to work on someone’s repository and make some changes, you should fork it first. Forking a repository, creates a copy of the project in you own GitHub account, allowing you to make changes and, potentially, contributing to the code/work of others.\n\ngh cliGitHub Desktop\n\n\nGo to the location where you want to store the repository and run: gh repo clone username/repositoryname Replace username/repositoryname with the actual repository path on GitHub.\n\n\nClick File &gt; Clone repository, search for the repository, and choose a local path.\n\n\n\n\n\n\nMaking changes and committing\nA key part of version control is recording the changes in the repository. Once you have created or deleted files, or made any changes, you need to commit them to save a snapshot of your work. In the diagram below, each dot is a commit with a set of changes.\n\n\n\nGit Workflow. From: Git for Data Science by Juha Kiili\n\n\nTo commit changes, you will first need to stage the files containing the changes. Staging means selecting what goes into the\n\nFrom terminalGitHub Desktop\n\n\nFrom the terminal, you can stage a file with the following code:\ngit add &lt;filename&gt;\nAlternatively, if you want to stage all files you can use\ngit add .\nThen, to finally commit changes, use the following code:\ngit commit -m \"Describe your changes\"\nIt is good practice to use concise but clear messages to describe what the change was.\n\n\nIn GitHub Desktop, changes are shown automatically. You may select the files that you want to include in the commit (stage them). Add a descriptive message and click “Commit to main”.\n\n\n\n\n\n\nPushing changes to GitHub\nUsing git gives you full control of the version control process. This means, that you decide when to publish/synchronise what you have done to the cloud. To update a repository on GitHub with your local commits, push your changes:\n\nFrom terminalGitHub Desktop\n\n\nFrom the terminal, use the following code to push your changes to the cloud:\n  git push\n\n\nClick “Push origin”.\n\n\n\n\n\n\nCollaboration with GitHub\nGitHub enables collaboration by allowing multiple people to work on the same repository. You can use Issues and Discussions to communicate. Imagine that you are working on some analysis in a team. One person in the team identifies a problem with the analysis. That person can open an issue to inform the rest of the team about this problem.\n\nFrom terminalGitHub web\n\n\nUsing the command line, you can create an issue by running:\ngh issue create\n\n\nOn the repository’s site, go to the Issues tab, and then create an issue.\n\n\n\n\n\n\nBranches and pull requests\nBranches let you work on new features or fixes without affecting the main codebase. When you create a branch, you effectively create a snapshot of the project at that point and use it as a starting point. It is recommended that you create a branch based on an existing issue, so there is some traceability of why there is a new variation of the project.\nEach issue is assigned a unique numeric ID that you can use to create a branch:\n\nFrom terminalGitHub web\n\n\nTo list all the issues in your repository you can run:\ngh issue list\nTo create a branch from an issue, e.g. #3, you can run:\ngh issue develop 3 --checkout\nUsing --checkout will move you from the main version of the project to the version where you are going to do the work to implement the solution to the issue. You can now start working and committing all necessary changes without affecting the main project. If you need to return to the main branch, you can run git checkout main.\n\n\nIf you open the page of an issue in your repository, you should be able to create a branch from the Development section in the side panel on the right.\n\nThen switch to the branch from the home page of the repository.\n\n\n\n\nOnce you have finished working with your branch, you can create a pull request so the changes are incorporated into the main version.\n\nFrom terminalGitHub web\n\n\nUsing the command line, you can create a pull request by running:\ngh pr create\n\n\nIn GitHub Desktop, every time you commit a change on a different branch to main, it will ask you if you want to create a pull request.\n\n\n\nAfter creating a pull request, the owner of the repository, reviews and approves your contribution.\n\n\nMerging changes\nif you are the owner of a repository and you receive a pull request. You can review it and merge it into the main branch.\n\nOn GitHub, click “Merge pull request”.\nLocally, use:\ngh pr merge 1\n\n\n\nResolving conflicts\nConflicts occur when changes in different branches overlap. Git will mark the conflicting files.\n\nOpen the file, look for conflict markers (&lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;), and edit to resolve.\nAfter resolving, add and commit the file:\ngit add &lt;filename&gt;\ngit commit\n\n\n\nAutomated workflows with GitHub Actions\nGitHub Actions lets you automate tasks like testing or deployment.\n\nAdd workflow files in .github/workflows/.\nExample: Run tests on every push.\n\n\n\nBest practices for collaboration, sharing code and data\n\nWrite clear commit messages.\nUse branches for features and fixes.\nKeep your repository organized with README, .gitignore, and license files.\nCommunicate using Issues and Discussions.\nReview code via pull requests.\nProtect sensitive data by not uploading secrets.\n\n\n\n\nIntroduction to Quarto\nQuarto is a next-generation open-source publishing system that allows you to combine text, code, and the output of that code into a single document. It is designed for technical and scientific communication, enabling the creation of reproducible documents that can be published in a wide variety of formats. You can use Quarto to produce reports, journal articles, presentation slides, books, and dashboards.\n\nQuarto projects\nQuarto documents are authored in a plain text format, using a markup language called Markdown. A markup language is a system for annotating a document using a set of tags or symbols to define the structure, formatting, and other properties of the text within a digital document. You might be familiar with commonly used markup languages like HTML or LaTeX. These languages make the text readable by both humans and machines. Since Quarto documents are based on plain text files, you can use Git and GitHub for version control.\n\n\n\n\n\n\nTip\n\n\n\nIf you are not familiar with using Markdown, take a look at the short course Communicate using Markdown on GitHub Skills.\n\n\nA Quarto project has two key parts:\n\nSource files: These are the individual documents written in Quarto Markdown, typically with a .qmd extension. They contain the narrative text, code chunks, other blocks, and a header for document-specific options.\n\n\n\n\nA qmd file of this website\n\n\n\nProject File (_quarto.yml): It’s a YAML (YAML Ain’t Markup Language) configuration file that lives in the project’s root directory. It defines global settings for all the documents in the project, such as the project type, metadata, output directories, and project-wide configuration for execution, style, and format. The contents of this file will depend on the type of project you are working on. Here is a sneak peek of the project file for this website:\n\n\n\n\nThe project file of this web\n\n\n\n\nCreating a Quarto project\nYou can create a Quarto project from scratch in an existing repository. First, let’s check that you can use quarto in your command line, and the version you have installed. If you run quarto -v in your shell, you should get the version of Quarto you have installed.\nPS C:\\temp\\tdscience&gt; quarto -v\n1.7.34\nTo create a new project in an existing directory, follow these steps:\n\nGo to your repository with cd &lt;path to repo&gt;\nRun quarto create\nChoose the name and type of project\nOpen the project in your preferred IDE.\n\nAs you see in the following code, Quarto will automatically create a source file and the project file.\nPS C:\\temp&gt; quarto create\n? Create » project\n? Type » default\n? Directory » my-first-quarto-project\n? Title (my-first-quarto-project) » My first quarto project\nCreating project at C:\\temp\\my-first-quarto-project:\n  - Created _quarto.yml\n  - Created My first quarto project.qmd\n? Open With\n❯ positron\n  vscode\n  (don't open)\nYou can also create Quarto projects interactively from the IDE. If you are interested, explore the documentation for RStudio, VSCode, or Positron.\n\n\nBlocks/Chunks\nBlocks in the qmd files are sections that are processed and formatted in a specific way. Blocks can contain code that can be processed in different ways. Chunks are delimited with ``` at the top and bottom, like this:\n```\nThis is a block\n```\nBlocks allow you to include content in HTML or LaTeX in the qmd files as raw code. Specifically for equations, you can use $$ as a delimiter. You can find more useful information on how to use Markdown in Quarto in the Quarto documentation.\n\n\nCode chunks and settings\nCode chunks that have the language name between braces at the start are executed as if you run the code in the console. For example:\n\nRPython\n\n\n```{r}\n# this is a code chunk/block that executes R code\na &lt;- 1 + 3\na\n```\n\n\n```{python}\n# this is a code chunk/block that executes python code\na = 1 + 3\nprint(a)\n```\n\n\n\nThere are several execution options that are useful, for example, to identify each code chunk, or to hide the code, the output, or both. These options are set in the code chunk header and allow you to precisely manage what is visible to the reader. As an example, the following code will hide the source code and only the output Hello World! will be visible in the rendered document.\n\nRPython\n\n\n```{r}\n#| label: hello-block-r\n#| echo: false\n\nprint(\"Hello World!\")\n```\n\n\n```{python}\n#| label: hello-block-python\n#| echo: false\n\nprint(\"Hello World!\")\n```\n\n\n\nSee the full details on execution options here. Other options allow you to reference the output of the block. For example, if your code is producing a figure, you can use the label for cross-referencing (more about this will be detailed in the next session), or to set the caption.\n\n\nPublishing your work\nQuarto enables you to generate a wide range of output formats from your project, whether you need an HTML report, a PDF article, a slideshow, or an entire website (like this one). From the command line, you can run quarto render to produce the rendered version of your project, or quarto preview to inspect your edits interactively.\nCombining Quarto and GitHub helps you make your research transparent, collaborative, and easy to share, ensuring that your work is not just published, but also verifiable and ready for future use.\n\n\n\nExercise\nFor this exercise you will not be creating a repository. Instead you will contribute to an existing repository. You may use the gh command line or the web interface from GitHub.\nFollow the following steps\n\nFork the following repository: juanfonsecaLS1/dstp-jf-git-exercise, and, If you have gh or GitHub Desktop installed, clone it in your machine.\nCreate an issue in your repository.\nCreate a branch related to that issue in your repository.\nIn the new branch Make a change in the file you are assigned during the session. Then commit the changes.\nIf you are working locally, push the changes to GitHub\nCreate a pull request",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#introduction-to-version-control",
    "href": "collaboration.html#introduction-to-version-control",
    "title": "Collaboration with Git & GitHub",
    "section": "Introduction to Version control",
    "text": "Introduction to Version control\n\nGit\nWorking with code/scripts/notebooks usually involves preparing them, revising and editing their content, and sharing with others. After completing at least one round of this process you can end up with several different versions of the same file. Are you familiar with Figure 1?\n\n\n\n\n\n\nFigure 1: Version control. From: programmerhumor.io\n\n\n\nGit is a great tool that tracks changes to files over time, especially in text-based files such as scripts, allowing multiple people to work on the same project without overwriting each other’s work. When Git is used as a version control system, a full copy of the entire project history is stored, making it easy to keep track of any changes, and even revert any changes. By using Git, it is possible to have different alternative versions of the same project, i.e. repository, without the need for independent files or folders for each version.\n\n\n\nGit Workflow. From: Git for Data Science by Juha Kiili\n\n\n\n\nGitHub\nGitHub is a platform that provides hosting for Git repositories. As a cloud-based service GitHub works as a Hub for storing, sharing and collaborating with others. Some tools in GitHub, like pull requests for proposing changes, reviews for asking others to check your work, and issue tracking for monitoring things to be corrected or improved, ease the collaborative work in different projects. Other features (GitHub Actions) allow the automation of different processes, for example, building a web, and testing and deploying code.\nTo learn more about the different elements in GitHub, you can start exploring the GitHub skills courses.\n\n\nWorking with GitHub\nAny Data Science project will benefit from having a clear file structure. The starting point will be a folder (a.k.a. repository) in which we will store the code, data and other relevant files. We are going to use both Git and GitHub for keeping track of all changes.\nYou might already be familiar with some key terms in a typical Git workflow: clone, commit, push, pull, or branch. Here is a useful cheat sheet.\nThere are two main ways of working with GitHub repositories in your machine: the gh command-line tool from the shell and the GitHub desktop graphical user interface. It is also possible to use the built-in IDEs’ extensions, but they generally have fewer features available. We will explore the different actions in the next session.\n\n\nNavigating GitHub\n\nUsing the gh command line interface (CLI)\nYou can search repos, commits, issues, pull requests, and code with the gh CLI tool. For example, to search for repositories related to “transport” sorted by the number of stars, you can run:\ngh search repos --topic transport --sort stars --limit 5\nThat outputs the following:\nShowing 5 of 1081 repositories\n\nNAME                    DESCRIPTION                                                                                   VISIBILITY  UPDATED             \ngboeing/osmnx           Download, model, analyze, and visualize street networks and other geospatial features fro...  public      about 10 hours ago\neclipse-sumo/sumo       Eclipse SUMO is an open source, highly portable, microscopic and continuous traffic simul...  public      about 19 minutes ago\nHaivision/srt           Secure, Reliable, Transport                                                                   public      about 6 hours ago\nenisdenjo/graphql-ws    Coherent, zero-dependency, lazy, simple, GraphQL over WebSocket Protocol compliant server...  public      about 6 hours ago\ngboeing/osmnx-examples  Gallery of OSMnx tutorials, usage examples, and feature demonstrations.                       public      about 16 hours ago\nYou can search for repos related to transport data science with the following and similar commands, as shown in Figure 2.\ngh search repos \"transport data science\" --sort stars --limit 5\n\n\n\n\n\n\nFigure 2: Search results for transport data science repositories on GitHub using the gh CLI\n\n\n\nSee the gh CLI manual for more details.\n\n\nExploring GitHub’s web interface\nAfter you have logged into github.com, you can use the web application to explore open source software. You can search for people’s profiles and repositories (the public ones) using the search bar. Try looking for a topic, package, or researcher/developer whose work interests you.\n\n\n\n\n\nWhen you access any public repository, you will typically see the same information in a similar layout:\n\n\n\n\n\n\nFigure 3\n\n\n\nGitHub organizes a repository’s content and collaboration tools into several key tabs. These tabs act as a dashboard, each providing a different view of the project’s status and activity.\n\n\nThe Main Tabs\n\nCode: This is the repository’s home page. It displays the project’s file and folder structure as it currently exists on the main branch. You can browse and view all the code, read the README file, and see the latest commits, providing a snapshot of the project’s current state.\nIssues: This tab is a central hub for tracking tasks, bugs, and feature requests. It’s a key collaboration tool where developers can open new issues to report problems, ask questions, or propose new ideas. The discussion around an issue is contained in a single thread, keeping conversations organized and searchable.\nPull requests: When a contributor wants to merge their changes from one branch into another, they create a pull request. This tab lists all open, closed, and merged pull requests. Pull requests are where code review happens; collaborators can discuss the proposed changes, add comments, and approve the code before it is integrated into the main project.\nDiscussions: This tab is a more free-form space for conversations that are not tied to a specific bug or feature. It is a place for general questions, project announcements, or sharing ideas with the community. Think of it as a forum built right into the repository, allowing for broader, non-code-related conversations.\n\n\n\n\nCreating and managing repositories\nYou can create a repository from scratch or using an existing folder. The following instructions show the basic process for creating a new repository, which will create a Git repository on your machine and upload it to GitHub.\n\n\n\n\n\n\nTip\n\n\n\nYou can use the gh command line interface (CLI) or a graphical user interface (GUI) like GitHub Desktop to create and manage repositories.\nWhile both approaches work, we recommend using the gh CLI because, after you have learned the commands, it is faster, more flexible, and easier to automate repetitive tasks.\nIf you want to create a repository using an existing folder, make sure to navigate to that folder in your terminal before running the gh repo create command.\n\n\n\ngh CLIGitHub Desktop\n\n\nTo create a repository from scratch, go to the location where you want to create your project using the shell, then run gh repo create to access the interactive mode.\nWe will select the first option:\n? What would you like to do?  [Use arrows to move, type to filter] \n&gt; Create a new repository on github.com from scratch\n  Create a new repository on github.com from a template repository\n  Push an existing local repository to github.com\nAssign a name. Remember that this will create a new folder with that name. We will call it myrepository.\n? Repository name\nNow select the owner of the repository, in this case, your username on GitHub.\n? Repository owner  [Use arrows to move, type to filter]\n&gt; yourGHname\nYou can provide a description for the repository. This can be edited afterwards.\n? Repository owner yourGHname\n? Description\nYou can choose whether your repository will be private or public. This can also be edited afterwards.\n? Visibility  [Use arrows to move, type to filter]\n&gt; Public\n  Private\nThe next steps will ask if you want to add README, .gitignore, and license files to your repository. A README file typically explains what the project is, why it is useful, and how others can get started using or contributing to it. A .gitignore file is a plain text file that tells Git which files or directories to intentionally ignore and not track. This is crucial for keeping a repository clean and secure. There are readily available templates based on programming languages; you can pick R in this case. Finally, the license file, if created, clearly states the legal terms under which the project’s code is distributed.\nAfter all questions, the interactive assistant will confirm if you want to create the repository.\n? Would you like to add a README file? Yes\n? Would you like to add a .gitignore? Yes\n? Choose a .gitignore template R\n? Would you like to add a license? Yes\n? Choose a license GNU Affero General Public License v3.0\n? This will create \"myrepository\" as a public repository on github.com. Continue? (Y/n) \nConfirm your repository and explore its contents!\n\n\nOpen the GitHub Desktop app. Click on the File menu and select New repository...\n\nA window asking for the details of your repository will appear.\n\nA .gitignore file is a plain text file that tells Git which files or directories to intentionally ignore and not track. This is crucial for keeping a repository clean and secure. There are readily available templates based on programming languages; you can pick R in this case. Finally, the license file, if created, clearly states the legal terms under which the project’s code is distributed.\nThis process will create the repository locally. In order to publish it on GitHub, you have to click on Publish repository.\n\n\n\n\nOnce your repository is created, you should be able to see it online. To access it, click on the Repositories tab in your profile page and select the repository you just created. You can see a list of repositories in your profile page by clicking on the Repositories tab, or typing github.com/username?tab=repositories in your browser, replacing username with your GitHub username. To see robinlovelace’s repositories, for example, you can type the following into your browser: github.com/Robinlovelace?tab=repositories.\n\n\nIf you want to create a repository from an existing project, you will need to initialize your repository. For this, go to the folder where you have your project with cd &lt;folder path&gt;, and run git init. This will create a local repository.\n\n\n\n\n\n\nImportant\n\n\n\nTo be able to use git in the command line, you need to have installed it from here\n\n\n\n\nCloning and Forking repositories\nTo work on a project from GitHub, you first need to create a local copy of the project/repository in your machine. This is referred as cloning the repository. Cloning creates an identical copy of the project, with all the files and their history. If you want to work on someone’s repository and make some changes, you should fork it first. Forking a repository, creates a copy of the project in you own GitHub account, allowing you to make changes and, potentially, contributing to the code/work of others.\n\ngh cliGitHub Desktop\n\n\nGo to the location where you want to store the repository and run: gh repo clone username/repositoryname Replace username/repositoryname with the actual repository path on GitHub.\n\n\nClick File &gt; Clone repository, search for the repository, and choose a local path.\n\n\n\n\n\n\nMaking changes and committing\nA key part of version control is recording the changes in the repository. Once you have created or deleted files, or made any changes, you need to commit them to save a snapshot of your work. In the diagram below, each dot is a commit with a set of changes.\n\n\n\nGit Workflow. From: Git for Data Science by Juha Kiili\n\n\nTo commit changes, you will first need to stage the files containing the changes. Staging means selecting what goes into the\n\nFrom terminalGitHub Desktop\n\n\nFrom the terminal, you can stage a file with the following code:\ngit add &lt;filename&gt;\nAlternatively, if you want to stage all files you can use\ngit add .\nThen, to finally commit changes, use the following code:\ngit commit -m \"Describe your changes\"\nIt is good practice to use concise but clear messages to describe what the change was.\n\n\nIn GitHub Desktop, changes are shown automatically. You may select the files that you want to include in the commit (stage them). Add a descriptive message and click “Commit to main”.\n\n\n\n\n\n\nPushing changes to GitHub\nUsing git gives you full control of the version control process. This means, that you decide when to publish/synchronise what you have done to the cloud. To update a repository on GitHub with your local commits, push your changes:\n\nFrom terminalGitHub Desktop\n\n\nFrom the terminal, use the following code to push your changes to the cloud:\n  git push\n\n\nClick “Push origin”.\n\n\n\n\n\n\nCollaboration with GitHub\nGitHub enables collaboration by allowing multiple people to work on the same repository. You can use Issues and Discussions to communicate. Imagine that you are working on some analysis in a team. One person in the team identifies a problem with the analysis. That person can open an issue to inform the rest of the team about this problem.\n\nFrom terminalGitHub web\n\n\nUsing the command line, you can create an issue by running:\ngh issue create\n\n\nOn the repository’s site, go to the Issues tab, and then create an issue.\n\n\n\n\n\n\nBranches and pull requests\nBranches let you work on new features or fixes without affecting the main codebase. When you create a branch, you effectively create a snapshot of the project at that point and use it as a starting point. It is recommended that you create a branch based on an existing issue, so there is some traceability of why there is a new variation of the project.\nEach issue is assigned a unique numeric ID that you can use to create a branch:\n\nFrom terminalGitHub web\n\n\nTo list all the issues in your repository you can run:\ngh issue list\nTo create a branch from an issue, e.g. #3, you can run:\ngh issue develop 3 --checkout\nUsing --checkout will move you from the main version of the project to the version where you are going to do the work to implement the solution to the issue. You can now start working and committing all necessary changes without affecting the main project. If you need to return to the main branch, you can run git checkout main.\n\n\nIf you open the page of an issue in your repository, you should be able to create a branch from the Development section in the side panel on the right.\n\nThen switch to the branch from the home page of the repository.\n\n\n\n\nOnce you have finished working with your branch, you can create a pull request so the changes are incorporated into the main version.\n\nFrom terminalGitHub web\n\n\nUsing the command line, you can create a pull request by running:\ngh pr create\n\n\nIn GitHub Desktop, every time you commit a change on a different branch to main, it will ask you if you want to create a pull request.\n\n\n\nAfter creating a pull request, the owner of the repository, reviews and approves your contribution.\n\n\nMerging changes\nif you are the owner of a repository and you receive a pull request. You can review it and merge it into the main branch.\n\nOn GitHub, click “Merge pull request”.\nLocally, use:\ngh pr merge 1\n\n\n\nResolving conflicts\nConflicts occur when changes in different branches overlap. Git will mark the conflicting files.\n\nOpen the file, look for conflict markers (&lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;), and edit to resolve.\nAfter resolving, add and commit the file:\ngit add &lt;filename&gt;\ngit commit\n\n\n\nAutomated workflows with GitHub Actions\nGitHub Actions lets you automate tasks like testing or deployment.\n\nAdd workflow files in .github/workflows/.\nExample: Run tests on every push.\n\n\n\nBest practices for collaboration, sharing code and data\n\nWrite clear commit messages.\nUse branches for features and fixes.\nKeep your repository organized with README, .gitignore, and license files.\nCommunicate using Issues and Discussions.\nReview code via pull requests.\nProtect sensitive data by not uploading secrets.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#introduction-to-quarto",
    "href": "collaboration.html#introduction-to-quarto",
    "title": "Collaboration with Git & GitHub",
    "section": "Introduction to Quarto",
    "text": "Introduction to Quarto\nQuarto is a next-generation open-source publishing system that allows you to combine text, code, and the output of that code into a single document. It is designed for technical and scientific communication, enabling the creation of reproducible documents that can be published in a wide variety of formats. You can use Quarto to produce reports, journal articles, presentation slides, books, and dashboards.\n\nQuarto projects\nQuarto documents are authored in a plain text format, using a markup language called Markdown. A markup language is a system for annotating a document using a set of tags or symbols to define the structure, formatting, and other properties of the text within a digital document. You might be familiar with commonly used markup languages like HTML or LaTeX. These languages make the text readable by both humans and machines. Since Quarto documents are based on plain text files, you can use Git and GitHub for version control.\n\n\n\n\n\n\nTip\n\n\n\nIf you are not familiar with using Markdown, take a look at the short course Communicate using Markdown on GitHub Skills.\n\n\nA Quarto project has two key parts:\n\nSource files: These are the individual documents written in Quarto Markdown, typically with a .qmd extension. They contain the narrative text, code chunks, other blocks, and a header for document-specific options.\n\n\n\n\nA qmd file of this website\n\n\n\nProject File (_quarto.yml): It’s a YAML (YAML Ain’t Markup Language) configuration file that lives in the project’s root directory. It defines global settings for all the documents in the project, such as the project type, metadata, output directories, and project-wide configuration for execution, style, and format. The contents of this file will depend on the type of project you are working on. Here is a sneak peek of the project file for this website:\n\n\n\n\nThe project file of this web\n\n\n\n\nCreating a Quarto project\nYou can create a Quarto project from scratch in an existing repository. First, let’s check that you can use quarto in your command line, and the version you have installed. If you run quarto -v in your shell, you should get the version of Quarto you have installed.\nPS C:\\temp\\tdscience&gt; quarto -v\n1.7.34\nTo create a new project in an existing directory, follow these steps:\n\nGo to your repository with cd &lt;path to repo&gt;\nRun quarto create\nChoose the name and type of project\nOpen the project in your preferred IDE.\n\nAs you see in the following code, Quarto will automatically create a source file and the project file.\nPS C:\\temp&gt; quarto create\n? Create » project\n? Type » default\n? Directory » my-first-quarto-project\n? Title (my-first-quarto-project) » My first quarto project\nCreating project at C:\\temp\\my-first-quarto-project:\n  - Created _quarto.yml\n  - Created My first quarto project.qmd\n? Open With\n❯ positron\n  vscode\n  (don't open)\nYou can also create Quarto projects interactively from the IDE. If you are interested, explore the documentation for RStudio, VSCode, or Positron.\n\n\nBlocks/Chunks\nBlocks in the qmd files are sections that are processed and formatted in a specific way. Blocks can contain code that can be processed in different ways. Chunks are delimited with ``` at the top and bottom, like this:\n```\nThis is a block\n```\nBlocks allow you to include content in HTML or LaTeX in the qmd files as raw code. Specifically for equations, you can use $$ as a delimiter. You can find more useful information on how to use Markdown in Quarto in the Quarto documentation.\n\n\nCode chunks and settings\nCode chunks that have the language name between braces at the start are executed as if you run the code in the console. For example:\n\nRPython\n\n\n```{r}\n# this is a code chunk/block that executes R code\na &lt;- 1 + 3\na\n```\n\n\n```{python}\n# this is a code chunk/block that executes python code\na = 1 + 3\nprint(a)\n```\n\n\n\nThere are several execution options that are useful, for example, to identify each code chunk, or to hide the code, the output, or both. These options are set in the code chunk header and allow you to precisely manage what is visible to the reader. As an example, the following code will hide the source code and only the output Hello World! will be visible in the rendered document.\n\nRPython\n\n\n```{r}\n#| label: hello-block-r\n#| echo: false\n\nprint(\"Hello World!\")\n```\n\n\n```{python}\n#| label: hello-block-python\n#| echo: false\n\nprint(\"Hello World!\")\n```\n\n\n\nSee the full details on execution options here. Other options allow you to reference the output of the block. For example, if your code is producing a figure, you can use the label for cross-referencing (more about this will be detailed in the next session), or to set the caption.\n\n\nPublishing your work\nQuarto enables you to generate a wide range of output formats from your project, whether you need an HTML report, a PDF article, a slideshow, or an entire website (like this one). From the command line, you can run quarto render to produce the rendered version of your project, or quarto preview to inspect your edits interactively.\nCombining Quarto and GitHub helps you make your research transparent, collaborative, and easy to share, ensuring that your work is not just published, but also verifiable and ready for future use.",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "collaboration.html#exercise",
    "href": "collaboration.html#exercise",
    "title": "Collaboration with Git & GitHub",
    "section": "Exercise",
    "text": "Exercise\nFor this exercise you will not be creating a repository. Instead you will contribute to an existing repository. You may use the gh command line or the web interface from GitHub.\nFollow the following steps\n\nFork the following repository: juanfonsecaLS1/dstp-jf-git-exercise, and, If you have gh or GitHub Desktop installed, clone it in your machine.\nCreate an issue in your repository.\nCreate a branch related to that issue in your repository.\nIn the new branch Make a change in the file you are assigned during the session. Then commit the changes.\nIf you are working locally, push the changes to GitHub\nCreate a pull request",
    "crumbs": [
      "Collaboration"
    ]
  },
  {
    "objectID": "4-statistics/index.html",
    "href": "4-statistics/index.html",
    "title": "Statistics - Tasks",
    "section": "",
    "text": "In this part of the practical, we will use what we have learned so far to perform the same analysis you have already learned with other tools, but this time using R.\n\nDownload the datasets for this exercises and save them in your data folder:\n\n\nParkRun Performance Data.xlsx\nRunning Data.xlsx\n\n\nDownload the following scripts and try to run the code in them. Your job is to debug these scripts by fixing the intentional errors so they run correctly.\n\n\nScript 1: Excel Task (R, Python)\nScript 2: SPSS Task (R, Python)\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Statistics",
      "About this section"
    ]
  },
  {
    "objectID": "3-visualisation/slides.html#why-visualise",
    "href": "3-visualisation/slides.html#why-visualise",
    "title": "",
    "section": "Why Visualise?",
    "text": "Why Visualise?\n\nUnderstand patterns quickly\nCommunicate findings effectively\nIdentify outliers and anomalies\nExplore relationships"
  },
  {
    "objectID": "3-visualisation/slides.html#scatter-plots",
    "href": "3-visualisation/slides.html#scatter-plots",
    "title": "",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nShow relationships between two continuous variables"
  },
  {
    "objectID": "3-visualisation/slides.html#bar-plots",
    "href": "3-visualisation/slides.html#bar-plots",
    "title": "",
    "section": "Bar Plots",
    "text": "Bar Plots\nShow counts or comparisons across categories"
  },
  {
    "objectID": "3-visualisation/slides.html#box-plots",
    "href": "3-visualisation/slides.html#box-plots",
    "title": "",
    "section": "Box Plots",
    "text": "Box Plots\nShow distributions and identify outliers"
  },
  {
    "objectID": "3-visualisation/slides.html#using-plots",
    "href": "3-visualisation/slides.html#using-plots",
    "title": "",
    "section": "Using Plots",
    "text": "Using Plots\nPlots can also be assigned to objects for further modification or saving:\n\n# Save plot to object\nfinal_plot &lt;- my_boxplot + theme_classic()\n\nfinal_plot"
  },
  {
    "objectID": "3-visualisation/slides.html#exporting-plots",
    "href": "3-visualisation/slides.html#exporting-plots",
    "title": "",
    "section": "Exporting Plots",
    "text": "Exporting Plots\nYou can save your plots using ggsave():\n# Save the final plot as a PNG file\nggsave(\"final_plot.png\", plot = final_plot,  width = 15,  height = 10, units = \"cm\", dpi = 300)"
  },
  {
    "objectID": "3-visualisation/slides.html#key-resources",
    "href": "3-visualisation/slides.html#key-resources",
    "title": "",
    "section": "Key Resources",
    "text": "Key Resources\n\nR for Data Science - Chapter 3: Data Visualisation\nggplot2 Documentation\nR Graphics Cookbook\nVisualization for Social Data Science"
  },
  {
    "objectID": "3-visualisation/slides.html#key-takeaways",
    "href": "3-visualisation/slides.html#key-takeaways",
    "title": "",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n✅ Start with a basic canvas and build incrementally\n✅ Choose the right geom for your data type\n✅ Customise colours, size, and transparency strategically\n✅ Add informative titles and axis labels\n✅ Use themes to improve presentation\n✅ Layer multiple geoms for richer visualisations"
  },
  {
    "objectID": "3-visualisation/slides.html#python-content-optional",
    "href": "3-visualisation/slides.html#python-content-optional",
    "title": "",
    "section": "Python Content (Optional)",
    "text": "Python Content (Optional)\nIf you’re interested in Python, here are equivalent concepts"
  },
  {
    "objectID": "2-manipulation/tasks.html",
    "href": "2-manipulation/tasks.html",
    "title": "Data Wrangling - Tasks",
    "section": "",
    "text": "In this section, we will practice data wrangling using R and the dplyr package from the tidyverse. Follow the steps below to manipulate and explore a dataset.\n\nCreate a new R script in your scripts folder and name it 2-data-wrangling-and-visualization.R.\nLoad the tidyverse package by adding the following line at the top of your script:\nlibrary(tidyverse)\nDownload the crashes file (here) and save it in your data folder.\nRead the crashes dataset into R using the read_csv() function and assign it to a variable named crashes:\ncrashes &lt;- read_csv(\"data/crashes.csv\")\nExplore the dataset:\n\nUse the head() function to view the first few rows of the dataset.\nUse the str() function to understand the structure of the dataset.\nUse the summary() function to get a summary of the dataset.\n\nData Wrangling Tasks:\n\nCreate a new data.frame named crashes_filtered that includes only cyclists.\nCreate a new data.frame named crashes_dark that includes only crashes that occurred in dark conditions.\nCreate a new data.frame named crashes_dark_cyclist that includes only crashes that involved cyclists and occurred in dark conditions.\nCreate a summary table named crashes_by_type that shows the median age by casualty type.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Manipulation",
      "Tasks"
    ]
  },
  {
    "objectID": "2-manipulation/index.html",
    "href": "2-manipulation/index.html",
    "title": "Manipulation",
    "section": "",
    "text": "ReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Manipulation",
      "About this section"
    ]
  },
  {
    "objectID": "1-basics/slides.html#integrated-development-environments-ides",
    "href": "1-basics/slides.html#integrated-development-environments-ides",
    "title": "",
    "section": "Integrated Development Environments (IDEs)",
    "text": "Integrated Development Environments (IDEs)\nYour toolkit for writing code"
  },
  {
    "objectID": "1-basics/slides.html#the-fundamentals-of-r",
    "href": "1-basics/slides.html#the-fundamentals-of-r",
    "title": "",
    "section": "The fundamentals of R",
    "text": "The fundamentals of R\n\nhow to organize your work\nbasic data types and structures\nusing R for calculations"
  },
  {
    "objectID": "1-basics/slides.html#using-r",
    "href": "1-basics/slides.html#using-r",
    "title": "",
    "section": "Using R",
    "text": "Using R"
  },
  {
    "objectID": "1-basics/slides.html#control-flow",
    "href": "1-basics/slides.html#control-flow",
    "title": "",
    "section": "Control Flow",
    "text": "Control Flow\nMaking decisions and repeating tasks"
  },
  {
    "objectID": "1-basics/slides.html#using-packages-in-r",
    "href": "1-basics/slides.html#using-packages-in-r",
    "title": "",
    "section": "Using Packages in R",
    "text": "Using Packages in R\nPackages are collections of functions to extend capabilities: Different types of data/sources, different methods, more efficient coding, etc.\n\nSource: Storybench"
  },
  {
    "objectID": "1-basics/slides.html#key-takeaways",
    "href": "1-basics/slides.html#key-takeaways",
    "title": "",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n✅ Know your IDE (RStudio or VS Code)\n✅ Understand basic data types in R\n✅ Know the difference between data structures\n✅ Organize your work with folder structure\n✅ Use relative paths for portability\n✅ Control program flow with if statements and loops\n✅ Learn how to install and use packages\n✅ Know where to find documentation"
  },
  {
    "objectID": "1-basics/slides.html#python-content-optional",
    "href": "1-basics/slides.html#python-content-optional",
    "title": "",
    "section": "Python Content (Optional)",
    "text": "Python Content (Optional)\nIf you’re interested in Python, here are equivalent concepts"
  },
  {
    "objectID": "1-basics/slides.html#the-fundamentals-of-python",
    "href": "1-basics/slides.html#the-fundamentals-of-python",
    "title": "",
    "section": "The Fundamentals of Python",
    "text": "The Fundamentals of Python\nOrganising Your Work\nProject structure and file paths\nRecommended Folder Structure\n\n\nmy-project/\n├── data/\n│   ├── raw/              # Original data files\n│   └── processed/        # Cleaned data\n├── code/\n│   ├── analysis.py\n│   └── plots.py\n├── outputs/\n│   ├── figures/\n│   └── results/\n├── README.md\n└── requirements.txt\n\n\nTips:\n\nKeep your work organised for easy maintenance\nUse meaningful folder and file names\nKeep data separate from code and outputs\nKeep raw data unchanged; process copies instead"
  },
  {
    "objectID": "1-basics/slides.html#using-packages-in-python",
    "href": "1-basics/slides.html#using-packages-in-python",
    "title": "",
    "section": "Using Packages in Python",
    "text": "Using Packages in Python\nPackages are collections of functions to extend capabilities: Different types of data/sources, different methods, more efficient coding, etc."
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Before starting this practical session, you’ll need to set up a few essential tools. Don’t worry—we’ll keep this brief!",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#required-software",
    "href": "prerequisites.html#required-software",
    "title": "Prerequisites",
    "section": "Required Software",
    "text": "Required Software\n\nIf using AppsAnywhere\nIf you’re using AppsAnywhere (available on university computers or your own laptop):\n\nOpen AppsAnywhere on your computer\nSearch for and launch R first\nSearch for and launch RStudio (requires R to be installed)\nFor Python (optional), search for and launch Anaconda from AppsAnywhere\n\n\n\nIf installing on your own laptop\nThis approach is recommended if you want more control over your installations and if you plan to continue using these tools after the session:\n\n1. R and RStudio\nR is a programming language widely used for statistical computing and data science.\n\nDownload R from CRAN\nDownload RStudio Desktop (free) from Posit\n\n\n\n2. Python (Optional but Recommended)\nPython is another popular language for data science.\n\nDownload Python from python.org (version 3.8 or higher)\nOr install via Anaconda (includes many data science packages)",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#getting-help",
    "href": "prerequisites.html#getting-help",
    "title": "Prerequisites",
    "section": "Getting Help",
    "text": "Getting Help\nIf you encounter installation issues:\n\nCheck the RStudio Support page\nVisit Stack Overflow for troubleshooting\nAsk during the session!\n\n\n\n\n\n\n\nTipPro Tip\n\n\n\nIf you run into installation issues before the session, don’t spend too much time troubleshooting. We can help you during the practical!",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Data Science",
    "section": "",
    "text": "Welcome to this practical introduction to data science! This session is designed for MSc students at the Institute for Transport Studies who are new to data science.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#about-this-session",
    "href": "index.html#about-this-session",
    "title": "Introduction to Data Science",
    "section": "About This Session",
    "text": "About This Session\nIn this practical, you’ll get hands-on experience with data science tools. We’ll cover implementations primarily in R. Python versions of the contents are provided for reference in some cases.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#logistics",
    "href": "index.html#logistics",
    "title": "Introduction to Data Science",
    "section": "Logistics",
    "text": "Logistics\n\nDate: Friday 28th November 2025\nTime: 09:00 - 12:00 (3 hours)\nLocation: Computer Cluster (Check timetable for specific room)",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Introduction to Data Science",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n09:00 - 09:15\nWelcome & Setup: Introduction and getting ready\n\n\n09:15 - 09:45\nBasics: RStudio, Quarto, and basic syntax\n\n\n09:45 - 10:30\nManipulation: Cleaning and transforming data with dplyr\n\n\n10:30 - 10:45\nBreak\n\n\n10:45 - 11:30\nVisualisation: Creating plots with ggplot2\n\n\n11:30 - 11:50\nStatistics: Basic statistical analysis (R, SPSS, Excel)\n\n\n11:50 - 12:00\nWrap-up: Collaboration, AI tools and next steps",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#what-youll-learn",
    "href": "index.html#what-youll-learn",
    "title": "Introduction to Data Science",
    "section": "What You’ll Learn",
    "text": "What You’ll Learn\nThis session covers:\n\nPrerequisites: Tools and setup you need before getting started\nGitHub Copilot & AI Tools: Setting up for learning and coding more effectively\nPractical Exercises: Basic data science tasks using R\nNext Steps: Resources to help you continue learning data science",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Introduction to Data Science",
    "section": "Getting Started",
    "text": "Getting Started\nNavigate through the sections using the menu. We recommend following them in order if you’re new to data science.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "1-basics/index.html",
    "href": "1-basics/index.html",
    "title": "The Basics",
    "section": "",
    "text": "ReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Basics",
      "About this section"
    ]
  },
  {
    "objectID": "1-basics/tasks.html",
    "href": "1-basics/tasks.html",
    "title": "The Basics - Tasks",
    "section": "",
    "text": "We are going to start from scratch and build up some basic skills in R. Follow the steps below to get started.\n\n\n\n\n\n\nTip\n\n\n\nGet R and RStudio running (see Prerequisites if needed) before.\n\n\nSetting up your first(?) project:\n\nIn RStudio, go to File &gt; New Project....\n\nSelect New Directory.\nSelect New Project.\nName the project DS-intro-2025 and choose a directory to save it in (your OneDrive might be a good choice).\nClick Create Project.\n\nNavigate to the Files tab, and create two folders in the project directory: data and scripts.\n\nNow using the console only:\n\nType: print(\"Hello, world!\") and hit Enter to see the output.\nNow try: 2 + 2 and hit Enter.\nFind what the current working directory is by typing getwd() and hitting Enter.\nAssign the value 10 to a variable named my_number using the assignment operator &lt;- or =.\nPrint the value of my_number to the console. Did it work?\n\nNow, let’s create your first R script: 8. In RStudio, go to File &gt; New File &gt; R Script.\n\n\n\n\n\n\nNote\n\n\n\nR scripts allow you to write and save your code. You can run the code directly from the script, and it helps you keep your work organized.\nThink of the script as a recipe that you can follow again and again! If you want to repeat your analysis or share it with others, having it in a script makes it easy.\nAll lines in the script that start with # are comments. They are not executed as code but are there to help explain what the code does.\n\n\n\nSave the script in the scripts folder as 1-basics-intro.R.\nType the following code in the new script:\n# This is my first R script\nprint(\"Hello, world!\")\nmy_number &lt;- 10\nprint(my_number)\nRun the code in the script by placing your cursor on each line and pressing Ctrl + Enter (or Cmd + Enter on Mac). Observe the output in the console.\nCreate a vector with 1000 random numbers between 0 and 100. For this, you can use the runif() function. Assign this vector to a variable named random_numbers. Check how to specify the minimum and maximum values in the runif() function by typing ?runif in the console.\nInstall the tidyverse package by typing install.packages(\"tidyverse\") in the console. We won’t use it now, we will load it in the next part.\n\nOptional:\n\nCalculate the mean and standard deviation of the random_numbers vector using the mean() and sd() functions. Print the results to the console.\nSave your script by clicking File &gt; Save or pressing Ctrl + S (or Cmd + S on Mac).\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Basics",
      "Tasks"
    ]
  },
  {
    "objectID": "2-manipulation/slides.html#reading-data",
    "href": "2-manipulation/slides.html#reading-data",
    "title": "",
    "section": "Reading Data",
    "text": "Reading Data\nCSV files are a common format for storing tabular data. You can read them into R using the read.csv() function or the read_csv() function from the readr package.\n# Base R\ncrashes &lt;- read.csv(\"data/crashes.csv\")\n\n# Using readr (faster, better defaults)\nlibrary(readr)\ncrashes &lt;- read_csv(\"data/crashes.csv\")"
  },
  {
    "objectID": "2-manipulation/slides.html#initial-exploration-of-data",
    "href": "2-manipulation/slides.html#initial-exploration-of-data",
    "title": "",
    "section": "Initial Exploration of Data",
    "text": "Initial Exploration of Data\nUnderstand your data before analysis"
  },
  {
    "objectID": "2-manipulation/slides.html#filtering-rows-with-dplyr",
    "href": "2-manipulation/slides.html#filtering-rows-with-dplyr",
    "title": "",
    "section": "Filtering Rows with dplyr",
    "text": "Filtering Rows with dplyr\nSelecting specific rows based on conditions is a common task in data manipulation.\nlibrary(dplyr)\n\n# Filter rows where casualty_age &gt; 50\ncrashes |&gt;\n  filter(casualty_age &gt; 50)\n\n# Multiple conditions\ncrashes |&gt;\n  filter(dark == TRUE & casualty_age &gt; 30)\n\n# Filter by casualty type\ncrashes |&gt;\n  filter(casualty_type == \"pedestrian\")"
  },
  {
    "objectID": "2-manipulation/slides.html#selecting-columns-with-dplyr",
    "href": "2-manipulation/slides.html#selecting-columns-with-dplyr",
    "title": "",
    "section": "Selecting Columns with dplyr",
    "text": "Selecting Columns with dplyr\nYou may want to choose which variables to work with\nlibrary(dplyr)\n\n# Select specific columns\ncrashes |&gt;\n  select(casualty_type, casualty_age, vehicle_type)\n\n# Select columns containing certain text\ncrashes |&gt;\n  select(contains(\"casualty\"))\n\n# Rename while selecting\ncrashes |&gt;\n  select(age = casualty_age, vehicle = vehicle_type)"
  },
  {
    "objectID": "2-manipulation/slides.html#ordering-data-with-arrange",
    "href": "2-manipulation/slides.html#ordering-data-with-arrange",
    "title": "",
    "section": "Ordering Data with arrange()",
    "text": "Ordering Data with arrange()\nSort your data by column values\nlibrary(dplyr)\n\n# Sort by casualty age (ascending)\ncrashes |&gt;\n  arrange(casualty_age)\n\n# Sort in descending order\ncrashes |&gt;\n  arrange(desc(casualty_age))\n\n# Sort by multiple columns\ncrashes |&gt;\n  arrange(vehicle_type, desc(casualty_age))"
  },
  {
    "objectID": "2-manipulation/slides.html#creating-new-columns-with-mutate",
    "href": "2-manipulation/slides.html#creating-new-columns-with-mutate",
    "title": "",
    "section": "Creating New Columns with mutate()",
    "text": "Creating New Columns with mutate()\nAdd or modify variables\nlibrary(dplyr)\n\n# Create new columns\ncrashes |&gt;\n  mutate(\n    age_group = case_when(\n      casualty_age &lt; 18 ~ \"Child\",\n      casualty_age &lt; 65 ~ \"Adult\",\n      TRUE ~ \"Senior\"\n    ),\n    birth_year = 2024 - casualty_age\n  )"
  },
  {
    "objectID": "2-manipulation/slides.html#summarising-data-with-summarise",
    "href": "2-manipulation/slides.html#summarising-data-with-summarise",
    "title": "",
    "section": "Summarising Data with summarise()",
    "text": "Summarising Data with summarise()\nCalculate aggregate statistics\nlibrary(dplyr)\n\n# Simple summary\ncrashes |&gt;\n  summarise(\n    mean_age = mean(casualty_age, na.rm = TRUE),\n    median_age = median(casualty_age, na.rm = TRUE),\n    n_casualties = n()\n  )"
  },
  {
    "objectID": "2-manipulation/slides.html#grouped-summaries-with-group_by",
    "href": "2-manipulation/slides.html#grouped-summaries-with-group_by",
    "title": "",
    "section": "Grouped Summaries with group_by()",
    "text": "Grouped Summaries with group_by()\nCalculate statistics for each group\nlibrary(dplyr)\n\n# Summary by casualty type\ncrashes |&gt;\n  group_by(casualty_type) |&gt;\n  summarise(\n    mean_age = mean(casualty_age),\n    n_casualties = n(),\n    .groups = \"drop\"\n  )\n\n# Summary by multiple groups\ncrashes |&gt;\n  group_by(vehicle_type, dark) |&gt;\n  summarise(mean_age = mean(casualty_age), .groups = \"drop\")"
  },
  {
    "objectID": "2-manipulation/slides.html#combining-operations-with-the-pipe",
    "href": "2-manipulation/slides.html#combining-operations-with-the-pipe",
    "title": "",
    "section": "Combining Operations with the Pipe (|>)",
    "text": "Combining Operations with the Pipe (|&gt;)\nChain multiple operations together\nlibrary(dplyr)\n\n# Complex workflow\nresult &lt;- crashes |&gt;\n  filter(casualty_age &gt; 18) |&gt;\n  select(casualty_type, casualty_age, vehicle_type, dark) |&gt;\n  mutate(age_group = ifelse(casualty_age &gt; 50, \"Older\", \"Younger\")) |&gt;\n  group_by(vehicle_type, age_group) |&gt;\n  summarise(n_casualties = n(), .groups = \"drop\") |&gt;\n  arrange(desc(n_casualties))"
  },
  {
    "objectID": "2-manipulation/slides.html#exporting-data",
    "href": "2-manipulation/slides.html#exporting-data",
    "title": "",
    "section": "Exporting Data",
    "text": "Exporting Data\nSave your processed data to a new CSV file\nlibrary(readr)\n# Write to CSV\nwrite_csv(result, \"outputs/processed_crashes.csv\")"
  },
  {
    "objectID": "2-manipulation/slides.html#example-workflow",
    "href": "2-manipulation/slides.html#example-workflow",
    "title": "",
    "section": "Example Workflow",
    "text": "Example Workflow\nBringing it all together\nBreaking down complex workflows into steps with meaningful variable names makes code more readable and maintainable.\nlibrary(dplyr)\nlibrary(readr)\n\n# Step 1: Filter for dark conditions\ncrashes_dark &lt;- crashes |&gt;\n  filter(dark == TRUE)\n\n# Step 2: Select relevant columns\ncrashes_dark_subset &lt;- crashes_dark |&gt;\n  select(casualty_type, casualty_age, vehicle_type)\n\n# Step 3: Create age categories\ncrashes_with_ages &lt;- crashes_dark_subset |&gt;\n  mutate(age_category = case_when(\n    casualty_age &lt; 25 ~ \"Young\",\n    casualty_age &lt; 65 ~ \"Middle-aged\",\n    TRUE ~ \"Older\"\n  ))\n\n# Step 4: Group and summarise\nsummary_by_type &lt;- crashes_with_ages |&gt;\n  group_by(casualty_type, age_category) |&gt;\n  summarise(\n    n_casualties = n(),\n    mean_age = mean(casualty_age),\n    .groups = \"drop\"\n  )\n\n# Step 5: Order results\nfinal_summary &lt;- summary_by_type |&gt;\n  arrange(desc(n_casualties))\n\nfinal_summary\n\n# Step 6: Export results\nwrite_csv(final_summary, \"outputs/dark_condition_summary.csv\")\nGood practice: Use descriptive variable names that show the transformation at each step!"
  },
  {
    "objectID": "2-manipulation/slides.html#key-takeaways",
    "href": "2-manipulation/slides.html#key-takeaways",
    "title": "",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n✅ Load and explore data before analysis\n✅ Filter rows based on conditions\n✅ Select and rename columns strategically\n✅ Create new variables with meaningful names\n✅ Group and summarise data for insights\n✅ Chain operations with the pipe operator (|&gt;)\n✅ Break complex workflows into named steps\n✅ Export processed data for sharing"
  },
  {
    "objectID": "2-manipulation/slides.html#python-content-optional",
    "href": "2-manipulation/slides.html#python-content-optional",
    "title": "",
    "section": "Python Content (Optional)",
    "text": "Python Content (Optional)\nIf you’re interested in Python, here are equivalent concepts\nReading Data in Python\nCSV files are read similarly in Python using pandas\nimport pandas as pd\n\n# Read CSV file\ncrashes = pd.read_csv(\"data/crashes.csv\")"
  },
  {
    "objectID": "3-visualisation/index.html",
    "href": "3-visualisation/index.html",
    "title": "Visualisation",
    "section": "",
    "text": "ReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Visualisation",
      "About this section"
    ]
  },
  {
    "objectID": "3-visualisation/tasks.html",
    "href": "3-visualisation/tasks.html",
    "title": "3. Visualisation - Tasks",
    "section": "",
    "text": "In this section, we will practice data visualization using R and the ggplot2 package from the tidyverse. Follow the steps below to create various types of plots.\nUsing the same script 2-data-wrangling-and-visualization.R from the previous section, continue with the following tasks:\nIf you have loaded the tidyverse package and read in the crashes dataset, you can proceed to the next steps. ggplot2 is part of the tidyverse, so you don’t need to load it separately.\n\nBox Plot:\n\nCreate a box plot to visualise the distribution of ages for different casualty types in the crashes dataset.\nUse ggplot() to specify the dataset and aesthetics, and geom_boxplot() to create the box plot.\nAdd appropriate labels and a title to your plot.\nSave the box plot to an object named age_boxplot.\nDisplay the plot by calling the object name.\n\nBar Plot (Optional):\n\nCreate a bar plot showing the count of casualties by type (pedestrian, cyclist, cat).\nAdd custom colours and transparency to the bars.\nAdd appropriate labels and a title.\nSave the plot to an object named casualty_barplot.\n\nExport Your Plots:\n\nSave the box plot as a PNG file named age_boxplot.png using the ggsave() function.\nSave the bar plot as a PNG file named casualty_barplot.png.\nCheck the documentation for ggsave() by typing ?ggsave in the console.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright© 2025 Robin Lovelace & contributors",
    "crumbs": [
      "Visualisation",
      "Tasks"
    ]
  },
  {
    "objectID": "4-statistics/solutions.html",
    "href": "4-statistics/solutions.html",
    "title": "Statistics - Worked Solutions",
    "section": "",
    "text": "This page presents the worked solutions for the statistics tasks, showing how to perform the same analyses in both R and Python.",
    "crumbs": [
      "Statistics",
      "Worked Solutions"
    ]
  },
  {
    "objectID": "4-statistics/solutions.html#task-1-excel-data-analysis",
    "href": "4-statistics/solutions.html#task-1-excel-data-analysis",
    "title": "Statistics - Worked Solutions",
    "section": "Task 1: Excel Data Analysis",
    "text": "Task 1: Excel Data Analysis\nThis task involves reading data from an Excel file (ParkRunPerformanceData.xlsx), cleaning it, calculating summaries, and visualizing the distribution of run times.\n\nRPython\n\n\n\n\nCode\n# Loading the necessary libraries\nlibrary(tidyverse)\nlibrary(readxl)\n\n# Assigning the path to a variable\npath_to_file &lt;- \"../00_data/ParkRunPerformanceData.xlsx\" # Corrected path\n\n# Reading data from an Excel file\ndata &lt;- read_excel(path = path_to_file,\n                   sheet = \"Sheet1\",\n                   col_types = c(\"date\", \"numeric\"))\n\n# Exploring the data\ncat(\"---\\n--- Head of Data ---\\n---\")\n\n\n---\n--- Head of Data ---\n---\n\n\nCode\nprint(head(data))\n\n\n# A tibble: 6 × 2\n  `Event Date`        `Run Time (minutes)`\n  &lt;dttm&gt;                             &lt;dbl&gt;\n1 2015-08-22 00:00:00                 20.6\n2 2015-08-15 00:00:00                 22.4\n3 2015-08-08 00:00:00                 27.0\n4 2015-08-01 00:00:00                 22.2\n5 2015-07-25 00:00:00                 24.8\n6 2015-07-18 00:00:00                 21.4\n\n\nCode\ncat(\"\\n--- Structure of Data ---\")\n\n\n\n--- Structure of Data ---\n\n\nCode\nstr(data)\n\n\ntibble [120 × 2] (S3: tbl_df/tbl/data.frame)\n $ Event Date        : POSIXct[1:120], format: \"2015-08-22\" \"2015-08-15\" ...\n $ Run Time (minutes): num [1:120] 20.6 22.4 27 22.2 24.8 ...\n\n\nCode\ncat(\"\\n--- Summary Statistics ---\")\n\n\n\n--- Summary Statistics ---\n\n\nCode\nsummary(data)\n\n\n   Event Date                  Run Time (minutes)\n Min.   :2012-08-04 00:00:00   Min.   :20.63     \n 1st Qu.:2013-09-07 00:00:00   1st Qu.:21.78     \n Median :2014-04-08 12:00:00   Median :23.07     \n Mean   :2014-04-07 21:48:00   Mean   :23.42     \n 3rd Qu.:2014-11-23 18:00:00   3rd Qu.:24.82     \n Max.   :2015-08-22 00:00:00   Max.   :31.13     \n\n\nCode\n# Rename the columns to ensure consistency and ease manipulation\nnames(data) &lt;- c(\"date\",\"runtime\")\n\n# Sorting the data\ndata_sorted &lt;- data |&gt; arrange(runtime)\ncat(\"\\n--- Sorted Data (Ascending) ---\")\n\n\n\n--- Sorted Data (Ascending) ---\n\n\nCode\nprint(head(data_sorted))\n\n\n# A tibble: 6 × 2\n  date                runtime\n  &lt;dttm&gt;                &lt;dbl&gt;\n1 2015-08-22 00:00:00    20.6\n2 2014-09-27 00:00:00    20.7\n3 2015-04-18 00:00:00    20.7\n4 2015-04-25 00:00:00    20.8\n5 2015-04-04 00:00:00    21.0\n6 2014-11-29 00:00:00    21.0\n\n\nCode\ndata_sorted_inv &lt;- data |&gt; arrange(-runtime)\ncat(\"\\n--- Sorted Data (Descending) ---\")\n\n\n\n--- Sorted Data (Descending) ---\n\n\nCode\nprint(head(data_sorted_inv))\n\n\n# A tibble: 6 × 2\n  date                runtime\n  &lt;dttm&gt;                &lt;dbl&gt;\n1 2013-10-19 00:00:00    31.1\n2 2013-07-20 00:00:00    30.6\n3 2013-03-16 00:00:00    29.4\n4 2014-02-01 00:00:00    27.5\n5 2013-01-12 00:00:00    27.4\n6 2013-06-15 00:00:00    27.3\n\n\nCode\n# Calculating the summaries manually \nsummary_dates &lt;- \n  data |&gt;\n  summarise(min_date = min(date),\n            max_date = max(date))\ncat(\"\\n--- Summary Dates ---\")\n\n\n\n--- Summary Dates ---\n\n\nCode\nprint(summary_dates)\n\n\n# A tibble: 1 × 2\n  min_date            max_date           \n  &lt;dttm&gt;              &lt;dttm&gt;             \n1 2012-08-04 00:00:00 2015-08-22 00:00:00\n\n\nCode\nsummary_runtimes &lt;- \n  data |&gt;\n  summarise(\n            count = n(),\n            mean_runtime = mean(runtime),\n            slowest = max(runtime),\n            fastest = min(runtime))\ncat(\"\\n--- Summary Runtimes ---\")\n\n\n\n--- Summary Runtimes ---\n\n\nCode\nprint(summary_runtimes)\n\n\n# A tibble: 1 × 4\n  count mean_runtime slowest fastest\n  &lt;int&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1   120         23.4    31.1    20.6\n\n\nCode\n# Rounding the run times to the nearest minute\ndata_rounded &lt;- data |&gt; \n  mutate(runtime_mins = round(x = runtime, digits = 0))\ncat(\"\\n--- Data with Rounded Runtimes ---\")\n\n\n\n--- Data with Rounded Runtimes ---\n\n\nCode\nprint(head(data_rounded))\n\n\n# A tibble: 6 × 3\n  date                runtime runtime_mins\n  &lt;dttm&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 2015-08-22 00:00:00    20.6           21\n2 2015-08-15 00:00:00    22.4           22\n3 2015-08-08 00:00:00    27.0           27\n4 2015-08-01 00:00:00    22.2           22\n5 2015-07-25 00:00:00    24.8           25\n6 2015-07-18 00:00:00    21.4           21\n\n\nCode\n# Counting the frequencies for each value\nfreq &lt;- data_rounded |&gt; \n  count(runtime_mins)\ncat(\"\\n--- Frequencies ---\")\n\n\n\n--- Frequencies ---\n\n\nCode\nprint(freq)\n\n\n# A tibble: 9 × 2\n  runtime_mins     n\n         &lt;dbl&gt; &lt;int&gt;\n1           21    19\n2           22    32\n3           23    17\n4           24    19\n5           25    15\n6           26    10\n7           27     5\n8           29     1\n9           31     2\n\n\nCode\n# A quick histogram\nhist(data_rounded$runtime_mins,breaks = 14:33, main = \"Quick Histogram of Run Times\")\n\n\n\n\n\nVarious Outputs from Excel Task (R)\n\n\n\n\nCode\n# A nicer histogram\ndata |&gt; \n  ggplot(aes(x = runtime))+\n  geom_histogram(binwidth = 1, col = \"white\",fill = \"steelblue\", alpha = 0.7)+\n  labs (x = \"Run time in seconds\",\n        y = \"frequency\",\n        title = \"Park Run Times Distribution\",\n        subtitle = \"Records from Aug 2012 to Aug 2015\",\n        caption = \"Source: Andrew Tomlinson\")+\n  scale_x_continuous(breaks = 14:33)+\n  geom_hline(yintercept = 0,linewidth = 1,col = \"grey30\")+\n  theme_minimal()+\n  theme(title = element_text(size = 15))\n\n\n\n\n\nVarious Outputs from Excel Task (R)\n\n\n\n\nCode\n# Have the run times improved?\n  # A different exploration\ndata |&gt; \n  ggplot(aes(x = date, y = runtime))+\n  geom_point() +  \n  geom_smooth(method = \"lm\")\n\n\n\n\n\nVarious Outputs from Excel Task (R)\n\n\n\n\n\n\n\n\nCode\nimport polars as pl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nsns.set_theme(style=\"whitegrid\")\n\n# Assigning the path to a variable\npath_to_file = \"../00_data/ParkRunPerformanceData.xlsx\" # Corrected path\n\n# Reading data from an Excel file\ndata = pl.from_pandas(pd.read_excel(path_to_file, sheet_name=\"Sheet1\"))\n\n# Exploring the data\nprint(\"---\\n--- Head of Data ---\\n---\")\n\n\n---\n--- Head of Data ---\n---\n\n\nCode\nprint(data.head())\n\n\nshape: (5, 2)\n┌─────────────────────┬────────────────────┐\n│ Event Date          ┆ Run Time (minutes) │\n│ ---                 ┆ ---                │\n│ datetime[ns]        ┆ f64                │\n╞═════════════════════╪════════════════════╡\n│ 2015-08-22 00:00:00 ┆ 20.633333          │\n│ 2015-08-15 00:00:00 ┆ 22.383333          │\n│ 2015-08-08 00:00:00 ┆ 26.966667          │\n│ 2015-08-01 00:00:00 ┆ 22.25              │\n│ 2015-07-25 00:00:00 ┆ 24.816667          │\n└─────────────────────┴────────────────────┘\n\n\nCode\nprint(\"\\n--- Schema ---\")\n\n\n\n--- Schema ---\n\n\nCode\nprint(data.schema)\n\n\nSchema({'Event Date': Datetime(time_unit='ns', time_zone=None), 'Run Time (minutes)': Float64})\n\n\nCode\nprint(\"\\n--- Summary Statistics ---\")\n\n\n\n--- Summary Statistics ---\n\n\nCode\nprint(data.describe())\n\n\nshape: (9, 3)\n┌────────────┬─────────────────────┬────────────────────┐\n│ statistic  ┆ Event Date          ┆ Run Time (minutes) │\n│ ---        ┆ ---                 ┆ ---                │\n│ str        ┆ str                 ┆ f64                │\n╞════════════╪═════════════════════╪════════════════════╡\n│ count      ┆ 120                 ┆ 120.0              │\n│ null_count ┆ 0                   ┆ 0.0                │\n│ mean       ┆ 2014-04-07 21:48:00 ┆ 23.420278          │\n│ std        ┆ null                ┆ 2.059807           │\n│ min        ┆ 2012-08-04 00:00:00 ┆ 20.633333          │\n│ 25%        ┆ 2013-09-14 00:00:00 ┆ 21.8               │\n│ 50%        ┆ 2014-04-12 00:00:00 ┆ 23.116667          │\n│ 75%        ┆ 2014-11-22 00:00:00 ┆ 24.816667          │\n│ max        ┆ 2015-08-22 00:00:00 ┆ 31.133333          │\n└────────────┴─────────────────────┴────────────────────┘\n\n\nCode\n# Rename the columns\nif len(data.columns) &gt;= 2:\n    data = data.rename({data.columns[0]: \"date\", data.columns[1]: \"runtime\"})\n\n# Sorting the data\ndata_sorted = data.sort(\"runtime\")\nprint(\"\\n--- Sorted Data (Ascending) ---\")\n\n\n\n--- Sorted Data (Ascending) ---\n\n\nCode\nprint(data_sorted.head())\n\n\nshape: (5, 2)\n┌─────────────────────┬───────────┐\n│ date                ┆ runtime   │\n│ ---                 ┆ ---       │\n│ datetime[ns]        ┆ f64       │\n╞═════════════════════╪═══════════╡\n│ 2015-08-22 00:00:00 ┆ 20.633333 │\n│ 2014-09-27 00:00:00 ┆ 20.666667 │\n│ 2015-04-18 00:00:00 ┆ 20.733333 │\n│ 2015-04-25 00:00:00 ┆ 20.816667 │\n│ 2015-04-04 00:00:00 ┆ 20.966667 │\n└─────────────────────┴───────────┘\n\n\nCode\ndata_sorted_inv = data.sort(\"runtime\", descending=True)\nprint(\"\\n--- Sorted Data (Descending) ---\")\n\n\n\n--- Sorted Data (Descending) ---\n\n\nCode\nprint(data_sorted_inv.head())\n\n\nshape: (5, 2)\n┌─────────────────────┬───────────┐\n│ date                ┆ runtime   │\n│ ---                 ┆ ---       │\n│ datetime[ns]        ┆ f64       │\n╞═════════════════════╪═══════════╡\n│ 2013-10-19 00:00:00 ┆ 31.133333 │\n│ 2013-07-20 00:00:00 ┆ 30.566667 │\n│ 2013-03-16 00:00:00 ┆ 29.416667 │\n│ 2014-02-01 00:00:00 ┆ 27.466667 │\n│ 2013-01-12 00:00:00 ┆ 27.45     │\n└─────────────────────┴───────────┘\n\n\nCode\n# Calculating summaries\nsummary_dates = data.select([\n    pl.col(\"date\").min().alias(\"min_date\"),\n    pl.col(\"date\").max().alias(\"max_date\")\n])\nprint(\"\\n--- Summary Dates ---\")\n\n\n\n--- Summary Dates ---\n\n\nCode\nprint(summary_dates)\n\n\nshape: (1, 2)\n┌─────────────────────┬─────────────────────┐\n│ min_date            ┆ max_date            │\n│ ---                 ┆ ---                 │\n│ datetime[ns]        ┆ datetime[ns]        │\n╞═════════════════════╪═════════════════════╡\n│ 2012-08-04 00:00:00 ┆ 2015-08-22 00:00:00 │\n└─────────────────────┴─────────────────────┘\n\n\nCode\nsummary_runtimes = data.select([\n    pl.len().alias(\"count\"),\n    pl.col(\"runtime\").mean().alias(\"mean_runtime\"),\n    pl.col(\"runtime\").max().alias(\"slowest\"),\n    pl.col(\"runtime\").min().alias(\"fastest\")\n])\nprint(\"\\n--- Summary Runtimes ---\")\n\n\n\n--- Summary Runtimes ---\n\n\nCode\nprint(summary_runtimes)\n\n\nshape: (1, 4)\n┌───────┬──────────────┬───────────┬───────────┐\n│ count ┆ mean_runtime ┆ slowest   ┆ fastest   │\n│ ---   ┆ ---          ┆ ---       ┆ ---       │\n│ u32   ┆ f64          ┆ f64       ┆ f64       │\n╞═══════╪══════════════╪═══════════╪═══════════╡\n│ 120   ┆ 23.420278    ┆ 31.133333 ┆ 20.633333 │\n└───────┴──────────────┴───────────┴───────────┘\n\n\nCode\n# Rounding the run times\ndata_rounded = data.with_columns(\n    pl.col(\"runtime\").round(0).alias(\"runtime_mins\")\n)\nprint(\"\\n--- Data with Rounded Runtimes ---\")\n\n\n\n--- Data with Rounded Runtimes ---\n\n\nCode\nprint(data_rounded.head())\n\n\nshape: (5, 3)\n┌─────────────────────┬───────────┬──────────────┐\n│ date                ┆ runtime   ┆ runtime_mins │\n│ ---                 ┆ ---       ┆ ---          │\n│ datetime[ns]        ┆ f64       ┆ f64          │\n╞═════════════════════╪═══════════╪══════════════╡\n│ 2015-08-22 00:00:00 ┆ 20.633333 ┆ 21.0         │\n│ 2015-08-15 00:00:00 ┆ 22.383333 ┆ 22.0         │\n│ 2015-08-08 00:00:00 ┆ 26.966667 ┆ 27.0         │\n│ 2015-08-01 00:00:00 ┆ 22.25     ┆ 22.0         │\n│ 2015-07-25 00:00:00 ┆ 24.816667 ┆ 25.0         │\n└─────────────────────┴───────────┴──────────────┘\n\n\nCode\n# Frequencies\nfreq = data_rounded.group_by(\"runtime_mins\").len().sort(\"runtime_mins\")\nprint(\"\\n--- Frequencies ---\")\n\n\n\n--- Frequencies ---\n\n\nCode\nprint(freq)\n\n\nshape: (9, 2)\n┌──────────────┬─────┐\n│ runtime_mins ┆ len │\n│ ---          ┆ --- │\n│ f64          ┆ u32 │\n╞══════════════╪═════╡\n│ 21.0         ┆ 19  │\n│ 22.0         ┆ 32  │\n│ 23.0         ┆ 17  │\n│ 24.0         ┆ 19  │\n│ 25.0         ┆ 15  │\n│ 26.0         ┆ 10  │\n│ 27.0         ┆ 5   │\n│ 29.0         ┆ 1   │\n│ 31.0         ┆ 2   │\n└──────────────┴─────┘\n\n\nCode\n# Nicer Histogram\nplt.figure(figsize=(10, 6))\nsns.histplot(\n    data=data_rounded.to_pandas(), \n    x=\"runtime\", \n    binwidth=1, \n    color=\"steelblue\", \n    edgecolor=\"white\", \n    alpha=0.7\n)\nplt.title(\"Park Run Times Distribution\\nRecords from Aug 2012 to Aug 2015\", fontsize=15)\nplt.xlabel(\"Run time in seconds\")\nplt.ylabel(\"frequency\")\nplt.xlim(14, 33)\n\n\n(14.0, 33.0)\n\n\nCode\nplt.axhline(0, color=\"grey\", linewidth=1)\nplt.figtext(0.8, 0.01, \"Source: Andrew Tomlinson\", wrap=True, horizontalalignment='center', fontsize=10) # Uncommented\nplt.show()\n\n\n\n\n\nVarious Outputs from Excel Task (Python)\n\n\n\n\nCode\n# Have the run times improved?\nplt.figure(figsize=(10, 6))\npdf = data.to_pandas()\n# Ensure date is numeric for regression plot\npdf['date_num'] = mdates.date2num(pdf['date'])\n\nsns.regplot(\n    data=pdf, \n    x='date_num', \n    y=\"runtime\", \n    scatter_kws={'s':10}, \n    line_kws={'color':'blue'}\n)\n# Fix x-axis to show dates\nax = plt.gca()\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\nplt.title(\"Run Times over Date\")\nplt.show() # Uncommented\n\n\n\n\n\nVarious Outputs from Excel Task (Python)",
    "crumbs": [
      "Statistics",
      "Worked Solutions"
    ]
  },
  {
    "objectID": "4-statistics/solutions.html#task-2-spss-data-analysis",
    "href": "4-statistics/solutions.html#task-2-spss-data-analysis",
    "title": "Statistics - Worked Solutions",
    "section": "Task 2: SPSS Data Analysis",
    "text": "Task 2: SPSS Data Analysis\nThis task analyzes running data originally handled in SPSS (RunningData.xlsx), including filtering, grouping, and statistical tests.\n\nRPython\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\n\npath_to_file &lt;- \"../00_data/RunningData.xlsx\"\ndata &lt;- read_excel(path = path_to_file, sheet = \"Sheet1\")\n\n# Rename columns\nnames(data) &lt;- c(\"position\", \"time\", \"age_cat\", \"gender\", \"prev_runs\")\n\n# Summaries\ncat(\"---\\n--- Summary of Time ---\")\n\n\n---\n--- Summary of Time ---\n\n\nCode\nsummary(data$time)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.90   24.40   27.88   28.31   32.00   43.23 \n\n\nCode\ncat(\"\\n--- Unique Age Categories ---\")\n\n\n\n--- Unique Age Categories ---\n\n\nCode\nunique(data$age_cat)\n\n\n [1] \"30-34\" \"20-24\" \"25-29\" \"40-44\" \"15-17\" \"35-39\" \"45-49\" \"50-54\" \"55-59\"\n[10] \"11-14\" \"10\"    \"60-64\" \"18-19\" \"65-69\" \"70-74\" \"75-79\"\n\n\nCode\n# Subset only adults \nchildren_cats &lt;- c(\"10\",\"11-14\",\"15-17\")\ndata_adults &lt;- data |&gt; \n  filter(!age_cat %in% children_cats)\n\ncat(\"\\n--- Unique Adult Age Categories ---\")\n\n\n\n--- Unique Adult Age Categories ---\n\n\nCode\nunique(data_adults$age_cat)\n\n\n [1] \"30-34\" \"20-24\" \"25-29\" \"40-44\" \"35-39\" \"45-49\" \"50-54\" \"55-59\" \"60-64\"\n[10] \"18-19\" \"65-69\" \"70-74\" \"75-79\"\n\n\nCode\ncat(\"\\n--- Summary of Adult Time ---\")\n\n\n\n--- Summary of Adult Time ---\n\n\nCode\nsummary(data_adults$time)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.90   24.34   27.68   28.16   31.72   42.68 \n\n\nCode\n# Analysis by gender\ncat(\"\\n--- Analysis by Gender ---\")\n\n\n\n--- Analysis by Gender ---\n\n\nCode\ndata_adults |&gt; \n  group_by(gender) |&gt; \n  summarise(min = min(time),\n            mean = mean(time),\n            median = median(time),\n            max = max(time))\n\n\n# A tibble: 2 × 5\n  gender   min  mean median   max\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 F       21.1  31.0   30.8  42.7\n2 M       16.9  25.2   24.7  40.8\n\n\nCode\n# Comparing distributions\ndata_adults |&gt; \n  ggplot(aes(x = time, fill = gender))+\n  geom_histogram(col = \"white\")+\n  facet_grid(gender~.)\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\ndata_adults |&gt; \n  ggplot(aes(x = time, col = gender))+\n  geom_density()\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\ndata_adults |&gt; \n  ggplot(aes(x = time, col = gender))+\n  geom_boxplot()\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\ndata_adults |&gt; \n  ggplot(aes(x = time, y = gender, col = gender))+\n  geom_violin()\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\n## Statistical tests\n# Extracting the data\ntimes_female_adults &lt;- data_adults |&gt; filter(gender == \"F\") |&gt; pull(time)\ntimes_male_adults &lt;- data_adults |&gt; filter(gender == \"M\") |&gt; pull(time)\n\ncat(\"\\n--- T-Test Results (Male vs Female) ---\")\n\n\n\n--- T-Test Results (Male vs Female) ---\n\n\nCode\nt.test(times_male_adults, times_female_adults)\n\n\n\n    Welch Two Sample t-test\n\ndata:  times_male_adults and times_female_adults\nt = -14.636, df = 521.03, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.622564 -5.055101\nsample estimates:\nmean of x mean of y \n 25.15512  30.99395 \n\n\nCode\n# Previous runs vs times\ndata_adults |&gt; \n  ggplot(aes(x = prev_runs, y = time))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\ndata_adults |&gt; \n  ggplot(aes(x = prev_runs, y =time, col = gender))+\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\ncat(\"\\n--- Correlation Test (Time vs Previous Runs) ---\")\n\n\n\n--- Correlation Test (Time vs Previous Runs) ---\n\n\nCode\ncor.test(data_adults$time, data_adults$prev_runs)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  data_adults$time and data_adults$prev_runs\nt = -5.4024, df = 522, p-value = 1.001e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3096642 -0.1473580\nsample estimates:\n       cor \n-0.2301107 \n\n\nCode\n# Finding the median of prev runs\nmedian_prev_runs &lt;- median(data_adults$prev_runs)\ncat(\"\\n--- Median Previous Runs ---\")\n\n\n\n--- Median Previous Runs ---\n\n\nCode\nprint(median_prev_runs)\n\n\n[1] 18\n\n\nCode\ndata_adults_pr_gr &lt;- data_adults |&gt; \n  mutate(pr_gr = prev_runs&gt;=median_prev_runs)\n\ncat(\"\\n--- Data with pr_gr group ---\")\n\n\n\n--- Data with pr_gr group ---\n\n\nCode\nprint(head(data_adults_pr_gr))\n\n\n# A tibble: 6 × 6\n  position  time age_cat gender prev_runs pr_gr\n     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;\n1        1  16.9 30-34   M             60 TRUE \n2        2  17.2 20-24   M             91 TRUE \n3        3  17.3 25-29   M             26 TRUE \n4        4  17.4 40-44   M             14 FALSE\n5        5  17.4 40-44   M              4 FALSE\n6        7  18.2 35-39   M             19 TRUE \n\n\nCode\n# a quick visual check\ndata_adults_pr_gr |&gt; \n  ggplot(aes(prev_runs,fill = pr_gr))+\n  geom_histogram()\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\n# Comparing times\ndata_adults_pr_gr |&gt; \n  ggplot(aes(x = time, col = pr_gr))+\n  geom_boxplot()\n\n\n\n\n\nVarious Outputs from SPSS Task (R)\n\n\n\n\nCode\n# Linear Model\n# Extract first two digits of age category for numeric age proxy\ndata_adults_lm &lt;- data_adults |&gt; \n  mutate(age = str_extract(age_cat, '^\\\\d{2}') |&gt; as.numeric())  \n\nmy_linear_model &lt;- lm(formula = \"time ~ age + gender + prev_runs\", data = data_adults_lm) \ncat(\"\\n--- Linear Model Summary ---\")\n\n\n\n--- Linear Model Summary ---\n\n\nCode\nsummary(my_linear_model)\n\n\n\nCall:\nlm(formula = \"time ~ age + gender + prev_runs\", data = data_adults_lm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.3003  -3.3456  -0.3801   2.5654  15.2136 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 30.198335   0.723994  41.711  &lt; 2e-16 ***\nage          0.043466   0.018523   2.347   0.0193 *  \ngenderM     -5.657628   0.395852 -14.292  &lt; 2e-16 ***\nprev_runs   -0.035480   0.007473  -4.748 2.66e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.473 on 520 degrees of freedom\nMultiple R-squared:  0.322, Adjusted R-squared:  0.3181 \nF-statistic: 82.31 on 3 and 520 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nCode\nimport polars as pl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport statsmodels.formula.api as smf\nimport numpy as np\n\nsns.set_theme(style=\"whitegrid\")\n\npath_to_file = \"../00_data/RunningData.xlsx\"\ndata = pl.from_pandas(pd.read_excel(path_to_file, sheet_name=\"Sheet1\"))\n\n# Rename columns\nif len(data.columns) &gt;= 5:\n    data = data.rename({\n        data.columns[0]: \"position\",\n        data.columns[1]: \"time\",\n        data.columns[2]: \"age_cat\",\n        data.columns[3]: \"gender\",\n        data.columns[4]: \"prev_runs\"\n    })\n\nprint(\"---\\n--- Head ---\")\n\n\n---\n--- Head ---\n\n\nCode\nprint(data.head())\n\n\nshape: (5, 5)\n┌──────────┬───────────┬─────────┬────────┬───────────┐\n│ position ┆ time      ┆ age_cat ┆ gender ┆ prev_runs │\n│ ---      ┆ ---       ┆ ---     ┆ ---    ┆ ---       │\n│ i64      ┆ f64       ┆ str     ┆ str    ┆ i64       │\n╞══════════╪═══════════╪═════════╪════════╪═══════════╡\n│ 1        ┆ 16.9      ┆ 30-34   ┆ M      ┆ 60        │\n│ 2        ┆ 17.166667 ┆ 20-24   ┆ M      ┆ 91        │\n│ 3        ┆ 17.3      ┆ 25-29   ┆ M      ┆ 26        │\n│ 4        ┆ 17.366667 ┆ 40-44   ┆ M      ┆ 14        │\n│ 5        ┆ 17.383333 ┆ 40-44   ┆ M      ┆ 4         │\n└──────────┴───────────┴─────────┴────────┴───────────┘\n\n\nCode\nprint(\"\\n--- Schema ---\")\n\n\n\n--- Schema ---\n\n\nCode\nprint(data.schema)\n\n\nSchema({'position': Int64, 'time': Float64, 'age_cat': String, 'gender': String, 'prev_runs': Int64})\n\n\nCode\nprint(\"\\n--- Summary ---\")\n\n\n\n--- Summary ---\n\n\nCode\nprint(data.describe())\n\n\nshape: (9, 6)\n┌────────────┬───────────┬───────────┬─────────┬────────┬───────────┐\n│ statistic  ┆ position  ┆ time      ┆ age_cat ┆ gender ┆ prev_runs │\n│ ---        ┆ ---       ┆ ---       ┆ ---     ┆ ---    ┆ ---       │\n│ str        ┆ f64       ┆ f64       ┆ str     ┆ str    ┆ f64       │\n╞════════════╪═══════════╪═══════════╪═════════╪════════╪═══════════╡\n│ count      ┆ 608.0     ┆ 608.0     ┆ 608     ┆ 608    ┆ 608.0     │\n│ null_count ┆ 0.0       ┆ 0.0       ┆ 0       ┆ 0      ┆ 0.0       │\n│ mean       ┆ 304.5     ┆ 28.31176  ┆ null    ┆ null   ┆ 26.036184 │\n│ std        ┆ 175.65876 ┆ 5.473712  ┆ null    ┆ null   ┆ 26.738812 │\n│ min        ┆ 1.0       ┆ 16.9      ┆ 10      ┆ F      ┆ 1.0       │\n│ 25%        ┆ 153.0     ┆ 24.4      ┆ null    ┆ null   ┆ 8.0       │\n│ 50%        ┆ 305.0     ┆ 27.883333 ┆ null    ┆ null   ┆ 17.0      │\n│ 75%        ┆ 456.0     ┆ 32.0      ┆ null    ┆ null   ┆ 34.0      │\n│ max        ┆ 608.0     ┆ 43.233333 ┆ 75-79   ┆ M      ┆ 189.0     │\n└────────────┴───────────┴───────────┴─────────┴────────┴───────────┘\n\n\nCode\nprint(\"\\n--- Time Summary ---\")\n\n\n\n--- Time Summary ---\n\n\nCode\nprint(data[\"time\"].describe())\n\n\nshape: (9, 2)\n┌────────────┬───────────┐\n│ statistic  ┆ value     │\n│ ---        ┆ ---       │\n│ str        ┆ f64       │\n╞════════════╪═══════════╡\n│ count      ┆ 608.0     │\n│ null_count ┆ 0.0       │\n│ mean       ┆ 28.31176  │\n│ std        ┆ 5.473712  │\n│ min        ┆ 16.9      │\n│ 25%        ┆ 24.4      │\n│ 50%        ┆ 27.883333 │\n│ 75%        ┆ 32.0      │\n│ max        ┆ 43.233333 │\n└────────────┴───────────┘\n\n\nCode\n# Subset adults\nchildren_cats = [\"10\", \"11-14\", \"15-17\"]\ndata_adults = data.filter(~pl.col(\"age_cat\").is_in(children_cats))\n\nprint(\"\\n--- Adult Age Categories ---\\n\")\n\n\n\n--- Adult Age Categories ---\n\n\nCode\nprint(data_adults[\"age_cat\"].unique())\n\n\nshape: (13,)\nSeries: 'age_cat' [str]\n[\n    \"30-34\"\n    \"75-79\"\n    \"40-44\"\n    \"65-69\"\n    \"20-24\"\n    …\n    \"50-54\"\n    \"35-39\"\n    \"45-49\"\n    \"25-29\"\n    \"60-64\"\n]\n\n\nCode\nprint(\"\\n--- Adult Time Summary ---\")\n\n\n\n--- Adult Time Summary ---\n\n\nCode\nprint(data_adults[\"time\"].describe())\n\n\nshape: (9, 2)\n┌────────────┬───────────┐\n│ statistic  ┆ value     │\n│ ---        ┆ ---       │\n│ str        ┆ f64       │\n╞════════════╪═══════════╡\n│ count      ┆ 524.0     │\n│ null_count ┆ 0.0       │\n│ mean       ┆ 28.163677 │\n│ std        ┆ 5.417044  │\n│ min        ┆ 16.9      │\n│ 25%        ┆ 24.35     │\n│ 50%        ┆ 27.683333 │\n│ 75%        ┆ 31.716667 │\n│ max        ┆ 42.683333 │\n└────────────┴───────────┘\n\n\nCode\n# Analysis by gender\nprint(\"\\n--- Analysis by Gender ---\")\n\n\n\n--- Analysis by Gender ---\n\n\nCode\nsummary_gender = data_adults.group_by(\"gender\").agg([\n    pl.col(\"time\").min().alias(\"min\"),\n    pl.col(\"time\").mean().alias(\"mean\"),\n    pl.col(\"time\").median().alias(\"median\"),\n    pl.col(\"time\").max().alias(\"max\")\n])\nprint(summary_gender)\n\n\nshape: (2, 5)\n┌────────┬──────┬───────────┬───────────┬───────────┐\n│ gender ┆ min  ┆ mean      ┆ median    ┆ max       │\n│ ---    ┆ ---  ┆ ---       ┆ ---       ┆ ---       │\n│ str    ┆ f64  ┆ f64       ┆ f64       ┆ f64       │\n╞════════╪══════╪═══════════╪═══════════╪═══════════╡\n│ M      ┆ 16.9 ┆ 25.155118 ┆ 24.725    ┆ 40.783333 │\n│ F      ┆ 21.1 ┆ 30.993951 ┆ 30.841667 ┆ 42.683333 │\n└────────┴──────┴───────────┴───────────┴───────────┘\n\n\nCode\n# Comparing distributions\ng = sns.FacetGrid(data_adults.to_pandas(), row=\"gender\", hue=\"gender\", aspect=2, height=3)\ng.map(sns.histplot, \"time\", edgecolor=\"white\")\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.figure(figsize=(10,6)) # Added figure size for consistency\nsns.kdeplot(data=data_adults.to_pandas(), x=\"time\", hue=\"gender\")\nplt.title(\"Density by Gender\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.figure(figsize=(10,6)) # Added figure size for consistency\nsns.boxplot(data=data_adults.to_pandas(), x=\"time\", hue=\"gender\")\nplt.title(\"Boxplot by Gender\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.figure(figsize=(10,6)) # Added figure size for consistency\nsns.violinplot(data=data_adults.to_pandas(), x=\"time\", y=\"gender\", hue=\"gender\")\nplt.title(\"Violin Plot by Gender\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\n## Statistical tests\n# Extracting the data\ntimes_female_adults = data_adults.filter(pl.col(\"gender\") == \"F\")[\"time\"]\ntimes_male_adults = data_adults.filter(pl.col(\"gender\") == \"M\")[\"time\"]\n\nprint(\"\\n--- Female Times (Head) ---\")\n\n\n\n--- Female Times (Head) ---\n\n\nCode\nprint(times_female_adults.head())\n\n\nshape: (10,)\nSeries: 'time' [f64]\n[\n    21.1\n    22.483333\n    22.983333\n    23.45\n    23.5\n    23.983333\n    24.016667\n    24.016667\n    24.016667\n    24.2\n]\n\n\nCode\nprint(\"\\n--- Male Times (Head) ---\")\n\n\n\n--- Male Times (Head) ---\n\n\nCode\nprint(times_male_adults.head())\n\n\nshape: (10,)\nSeries: 'time' [f64]\n[\n    16.9\n    17.166667\n    17.3\n    17.366667\n    17.383333\n    18.216667\n    18.333333\n    18.383333\n    18.483333\n    18.65\n]\n\n\nCode\nt_stat, p_val = stats.ttest_ind(times_male_adults, times_female_adults)\nprint(f\"\\n--- T-Test Results ---\\nt-statistic: {t_stat}\\np-value: {p_val}\")\n\n\n\n--- T-Test Results ---\nt-statistic: -14.627688831201171\np-value: 7.426339858226408e-41\n\n\nCode\n# Previous runs vs times\nplt.figure(figsize=(10,6)) # Added figure size for consistency\nsns.regplot(data=data_adults.to_pandas(), x=\"prev_runs\", y=\"time\")\nplt.title(\"Time vs Previous Runs\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.figure(figsize=(10,6)) # Added figure size for consistency\nsns.lmplot(data=data_adults.to_pandas(), x=\"prev_runs\", y=\"time\", hue=\"gender\")\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\nplt.title(\"Time vs Previous Runs by Gender\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\n# Correlation\ncorr, p_corr = stats.pearsonr(data_adults[\"time\"], data_adults[\"prev_runs\"])\nprint(f\"\\n--- Correlation Test ---\\ncorrelation: {corr}\\np-value: {p_corr}\")\n\n\n\n--- Correlation Test ---\ncorrelation: -0.23011066826185408\np-value: 1.0010219010793921e-07\n\n\nCode\n# Finding the median of prev runs\nmedian_prev_runs = data_adults[\"prev_runs\"].median()\nprint(f\"\\nMedian Previous Runs: {median_prev_runs}\")\n\n\n\nMedian Previous Runs: 18.0\n\n\nCode\ndata_adults_pr_gr = data_adults.with_columns(\n    (pl.col(\"prev_runs\") &gt;= median_prev_runs).alias(\"pr_gr\")\n)\n\nprint(\"\\n--- Data with pr_gr group ---\")\n\n\n\n--- Data with pr_gr group ---\n\n\nCode\nprint(data_adults_pr_gr.select([\"prev_runs\", \"pr_gr\"]).head())\n\n\nshape: (5, 2)\n┌───────────┬───────┐\n│ prev_runs ┆ pr_gr │\n│ ---       ┆ ---   │\n│ i64       ┆ bool  │\n╞═══════════╪═══════╡\n│ 60        ┆ true  │\n│ 91        ┆ true  │\n│ 26        ┆ true  │\n│ 14        ┆ false │\n│ 4         ┆ false │\n└───────────┴───────┘\n\n\nCode\n# a quick visual check\nplt.figure(figsize=(10,6))\nsns.histplot(data=data_adults_pr_gr.to_pandas(), x=\"prev_runs\", hue=\"pr_gr\", multiple=\"stack\")\nplt.title(\"Previous Runs Split\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\n# Comparing times\nplt.figure(figsize=(10,6))\nsns.boxplot(data=data_adults_pr_gr.to_pandas(), x=\"time\", hue=\"pr_gr\")\nplt.title(\"Time by Previous Runs Group\")\nplt.show()\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)\n\n\n\n\nCode\n# Linear Model\ndata_adults_lm = data_adults.with_columns(\n    pl.col(\"age_cat\").str.extract(r\"^(\\d{2})\", 1).cast(pl.Float64).alias(\"age\")\n)\n\nmodel = smf.ols(formula=\"time ~ age + gender + prev_runs\", data=data_adults_lm.to_pandas())\nresults = model.fit()\nprint(\"\\n--- Linear Model Summary ---\\n\")\n\n\n\n--- Linear Model Summary ---\n\n\nCode\nprint(results.summary())\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   time   R-squared:                       0.322\nModel:                            OLS   Adj. R-squared:                  0.318\nMethod:                 Least Squares   F-statistic:                     82.31\nDate:                Tue, 25 Nov 2025   Prob (F-statistic):           1.39e-43\nTime:                        14:34:34   Log-Likelihood:                -1526.5\nNo. Observations:                 524   AIC:                             3061.\nDf Residuals:                     520   BIC:                             3078.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept      30.1983      0.724     41.711      0.000      28.776      31.621\ngender[T.M]    -5.6576      0.396    -14.292      0.000      -6.435      -4.880\nage             0.0435      0.019      2.347      0.019       0.007       0.080\nprev_runs      -0.0355      0.007     -4.748      0.000      -0.050      -0.021\n==============================================================================\nOmnibus:                       27.598   Durbin-Watson:                   0.589\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               30.512\nSkew:                           0.578   Prob(JB):                     2.37e-07\nKurtosis:                       3.248   Cond. No.                         193.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nVarious Outputs from SPSS Task (Python)",
    "crumbs": [
      "Statistics",
      "Worked Solutions"
    ]
  },
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "GitHub Copilot & AI Tools",
    "section": "",
    "text": "AI-powered coding assistants can significantly accelerate your data science learning journey. Let’s explore how to use them effectively!",
    "crumbs": [
      "AI Tools"
    ]
  },
  {
    "objectID": "ai.html#github-copilot",
    "href": "ai.html#github-copilot",
    "title": "GitHub Copilot & AI Tools",
    "section": "GitHub Copilot",
    "text": "GitHub Copilot\nGitHub Copilot is an AI pair programmer that helps you write code faster and with fewer errors.\n\nWhat is GitHub Copilot?\n\nAI-powered code completion tool\nSuggests whole lines or blocks of code as you type\nUnderstands context from your code and comments\nTrained on billions of lines of public code\n\n\n\nFor Students\nGood news! Students get free access to GitHub Copilot:\n\nVisit GitHub Education\nApply for the Student Developer Pack\nVerify your student status\nAccess Copilot for free while you’re a student\n\n\n\nInstalling GitHub Copilot\nFor RStudio:\n\nYou can activate code completion via Tools -&gt; Global Options -&gt; Copilot.\n\nFor VS Code:\n\nInstall Visual Studio Code\nInstall the GitHub Copilot extension from the marketplace\nSign in with your GitHub account",
    "crumbs": [
      "AI Tools"
    ]
  },
  {
    "objectID": "ai.html#google-gemini",
    "href": "ai.html#google-gemini",
    "title": "GitHub Copilot & AI Tools",
    "section": "Google Gemini",
    "text": "Google Gemini\nGoogle Gemini is a powerful multimodal AI model that can assist with coding, data analysis, and more.\n\nFree Access for Students\nEligible students can get free access to Gemini Advanced for 12 months:\n\nVisit gemini.google/students\nClick on “Get the offer”\nSign in with your personal Google account (not your university email)\nVerify your student status via SheerID\nEnjoy 1 year of free access to Gemini Advanced\n\nNote: Requires being 18+ and enrolled at an eligible institution.",
    "crumbs": [
      "AI Tools"
    ]
  },
  {
    "objectID": "ai.html#best-practices",
    "href": "ai.html#best-practices",
    "title": "GitHub Copilot & AI Tools",
    "section": "Best Practices",
    "text": "Best Practices\n\n\n\n\n\n\nTipWriting Good Prompts\n\n\n\n\nWrite clear comments describing what you want to do\nUse descriptive variable names\nBreak complex tasks into smaller steps\n\n\n\nDOs ✅\n\nUse AI to understand error messages\nAsk AI to explain unfamiliar code\nUse suggestions to learn new approaches\nVerify AI-generated code before using it\n\nDON’Ts ❌\n\nDon’t blindly copy-paste without understanding\nDon’t use AI to do all your work (you won’t learn!)\nDon’t share sensitive data with AI tools\nDon’t assume AI code is always correct\n\n\n\n\n\n\n\nWarningCritical Thinking Required\n\n\n\nAI tools are powerful assistants, but they can make mistakes. Always review and test the code they generate!",
    "crumbs": [
      "AI Tools"
    ]
  },
  {
    "objectID": "ai.html#resources",
    "href": "ai.html#resources",
    "title": "GitHub Copilot & AI Tools",
    "section": "Resources",
    "text": "Resources\n\nGitHub Copilot Documentation\nGitHub Student Developer Pack\nEffective Copilot Prompts",
    "crumbs": [
      "AI Tools"
    ]
  }
]