--- 
title: "Statistics - Worked Solutions"
format:
  html:
    code-fold: true
---

This page presents the worked solutions for the statistics tasks, showing how to perform the same analyses in both R and Python.

::: callout-warning
## Before you proceed...

These are worked solutions. We strongly recommend attempting to debug the R and Python problem scripts in the [Tasks section](4-statistics/index.qmd) before reviewing these solutions. Learning to debug is a crucial data science skill!
:::

## Task 1: Excel Data Analysis

This task involves reading data from an Excel file (`ParkRunPerformanceData.xlsx`), cleaning it, calculating summaries, and visualizing the distribution of run times.

::: panel-tabset

### R

```{r}
#| label: excel-task-r
#| warning: false
#| message: false
#| fig-width: 10
#| fig-height: 6
#| fig-align: center
#| fig-cap: "Various Outputs from Excel Task (R)"

# Loading the necessary libraries
library(tidyverse)
library(readxl)

# Assigning the path to a variable
path_to_file <- "../00_data/ParkRunPerformanceData.xlsx" # Corrected path

# Reading data from an Excel file
data <- read_excel(path = path_to_file,
                   sheet = "Sheet1",
                   col_types = c("date", "numeric"))

# Exploring the data
cat("---\n--- Head of Data ---\n---")
print(head(data))

cat("\n--- Structure of Data ---")
str(data)

cat("\n--- Summary Statistics ---")
summary(data)


# Rename the columns to ensure consistency and ease manipulation
names(data) <- c("date","runtime")

# Sorting the data
data_sorted <- data |> arrange(runtime)
cat("\n--- Sorted Data (Ascending) ---")
print(head(data_sorted))

data_sorted_inv <- data |> arrange(-runtime)
cat("\n--- Sorted Data (Descending) ---")
print(head(data_sorted_inv))


# Calculating the summaries manually 
summary_dates <- 
  data |>
  summarise(min_date = min(date),
            max_date = max(date))
cat("\n--- Summary Dates ---")
print(summary_dates)

summary_runtimes <- 
  data |>
  summarise(
            count = n(),
            mean_runtime = mean(runtime),
            slowest = max(runtime),
            fastest = min(runtime))
cat("\n--- Summary Runtimes ---")
print(summary_runtimes)

# Rounding the run times to the nearest minute
data_rounded <- data |> 
  mutate(runtime_mins = round(x = runtime, digits = 0))
cat("\n--- Data with Rounded Runtimes ---")
print(head(data_rounded))


# Counting the frequencies for each value
freq <- data_rounded |> 
  count(runtime_mins)
cat("\n--- Frequencies ---")
print(freq)

# A quick histogram
hist(data_rounded$runtime_mins,breaks = 14:33, main = "Quick Histogram of Run Times")

# A nicer histogram
data |> 
  ggplot(aes(x = runtime))+
  geom_histogram(binwidth = 1, col = "white",fill = "steelblue", alpha = 0.7)+
  labs (x = "Run time in seconds",
        y = "frequency",
        title = "Park Run Times Distribution",
        subtitle = "Records from Aug 2012 to Aug 2015",
        caption = "Source: Andrew Tomlinson")+
  scale_x_continuous(breaks = 14:33)+
  geom_hline(yintercept = 0,linewidth = 1,col = "grey30")+
  theme_minimal()+
  theme(title = element_text(size = 15))

# Have the run times improved?
  # A different exploration
data |> 
  ggplot(aes(x = date, y = runtime))+
  geom_point() +  
  geom_smooth(method = "lm")
```

### Python

```{r}
#| include: false
# Install Python packages from requirements.txt
reticulate::virtualenv_install(
  packages = readLines("../requirements.txt"),
  ignore_installed = TRUE
)
```

```{python}
#| label: excel-task-py
#| warning: false
#| fig-width: 10
#| fig-height: 6
#| fig-align: center
#| fig-cap: "Various Outputs from Excel Task (Python)"

import polars as pl
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

sns.set_theme(style="whitegrid")

# Assigning the path to a variable
path_to_file = "../00_data/ParkRunPerformanceData.xlsx" # Corrected path

# Reading data from an Excel file
data = pl.from_pandas(pd.read_excel(path_to_file, sheet_name="Sheet1"))

# Exploring the data
print("---\n--- Head of Data ---\n---")
print(data.head())

print("\n--- Schema ---")
print(data.schema)

print("\n--- Summary Statistics ---")
print(data.describe())

# Rename the columns
if len(data.columns) >= 2:
    data = data.rename({data.columns[0]: "date", data.columns[1]: "runtime"})

# Sorting the data
data_sorted = data.sort("runtime")
print("\n--- Sorted Data (Ascending) ---")
print(data_sorted.head())

data_sorted_inv = data.sort("runtime", descending=True)
print("\n--- Sorted Data (Descending) ---")
print(data_sorted_inv.head())

# Calculating summaries
summary_dates = data.select([
    pl.col("date").min().alias("min_date"),
    pl.col("date").max().alias("max_date")
])
print("\n--- Summary Dates ---")
print(summary_dates)

summary_runtimes = data.select([
    pl.len().alias("count"),
    pl.col("runtime").mean().alias("mean_runtime"),
    pl.col("runtime").max().alias("slowest"),
    pl.col("runtime").min().alias("fastest")
])
print("\n--- Summary Runtimes ---")
print(summary_runtimes)

# Rounding the run times
data_rounded = data.with_columns(
    pl.col("runtime").round(0).alias("runtime_mins")
)
print("\n--- Data with Rounded Runtimes ---")
print(data_rounded.head())

# Frequencies
freq = data_rounded.group_by("runtime_mins").len().sort("runtime_mins")
print("\n--- Frequencies ---")
print(freq)

# Nicer Histogram
plt.figure(figsize=(10, 6))
sns.histplot(
    data=data_rounded.to_pandas(), 
    x="runtime", 
    binwidth=1, 
    color="steelblue", 
    edgecolor="white", 
    alpha=0.7
)
plt.title("Park Run Times Distribution\nRecords from Aug 2012 to Aug 2015", fontsize=15)
plt.xlabel("Run time in seconds")
plt.ylabel("frequency")
plt.xlim(14, 33)
plt.axhline(0, color="grey", linewidth=1)
plt.figtext(0.8, 0.01, "Source: Andrew Tomlinson", wrap=True, horizontalalignment='center', fontsize=10) # Uncommented
plt.show()

# Have the run times improved?
plt.figure(figsize=(10, 6))
pdf = data.to_pandas()
# Ensure date is numeric for regression plot
pdf['date_num'] = mdates.date2num(pdf['date'])

sns.regplot(
    data=pdf, 
    x='date_num', 
    y="runtime", 
    scatter_kws={'s':10}, 
    line_kws={'color':'blue'}
)
# Fix x-axis to show dates
ax = plt.gca()
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.title("Run Times over Date")
plt.show() # Uncommented
```

:::

## Task 2: SPSS Data Analysis

This task analyzes running data originally handled in SPSS (`RunningData.xlsx`), including filtering, grouping, and statistical tests.

::: panel-tabset

### R

```{r}
#| label: spss-task-r
#| warning: false
#| message: false
#| fig-width: 10
#| fig-height: 6
#| fig-align: center
#| fig-cap: "Various Outputs from SPSS Task (R)"

library(tidyverse)
library(readxl)

path_to_file <- "../00_data/RunningData.xlsx"
data <- read_excel(path = path_to_file, sheet = "Sheet1")

# Rename columns
names(data) <- c("position", "time", "age_cat", "gender", "prev_runs")

# Summaries
cat("---\n--- Summary of Time ---")
summary(data$time)
cat("\n--- Unique Age Categories ---")
unique(data$age_cat)

# Subset only adults 
children_cats <- c("10","11-14","15-17")
data_adults <- data |> 
  filter(!age_cat %in% children_cats)

cat("\n--- Unique Adult Age Categories ---")
unique(data_adults$age_cat)
cat("\n--- Summary of Adult Time ---")
summary(data_adults$time)

# Analysis by gender
cat("\n--- Analysis by Gender ---")
data_adults |> 
  group_by(gender) |> 
  summarise(min = min(time),
            mean = mean(time),
            median = median(time),
            max = max(time))

# Comparing distributions
data_adults |> 
  ggplot(aes(x = time, fill = gender))+
  geom_histogram(col = "white")+
  facet_grid(gender~.)

data_adults |> 
  ggplot(aes(x = time, col = gender))+
  geom_density()

data_adults |> 
  ggplot(aes(x = time, col = gender))+
  geom_boxplot()

data_adults |> 
  ggplot(aes(x = time, y = gender, col = gender))+
  geom_violin()

## Statistical tests
# Extracting the data
times_female_adults <- data_adults |> filter(gender == "F") |> pull(time)
times_male_adults <- data_adults |> filter(gender == "M") |> pull(time)

cat("\n--- T-Test Results (Male vs Female) ---")
t.test(times_male_adults, times_female_adults)

# Previous runs vs times
data_adults |> 
  ggplot(aes(x = prev_runs, y = time))+
  geom_point()+
  geom_smooth(method = "lm")

data_adults |> 
  ggplot(aes(x = prev_runs, y =time, col = gender))+
  geom_point() +
  geom_smooth(method = "lm")

cat("\n--- Correlation Test (Time vs Previous Runs) ---")
cor.test(data_adults$time, data_adults$prev_runs)

# Finding the median of prev runs
median_prev_runs <- median(data_adults$prev_runs)
cat("\n--- Median Previous Runs ---")
print(median_prev_runs)

data_adults_pr_gr <- data_adults |> 
  mutate(pr_gr = prev_runs>=median_prev_runs)

cat("\n--- Data with pr_gr group ---")
print(head(data_adults_pr_gr))

# a quick visual check
data_adults_pr_gr |> 
  ggplot(aes(prev_runs,fill = pr_gr))+
  geom_histogram()

# Comparing times
data_adults_pr_gr |> 
  ggplot(aes(x = time, col = pr_gr))+
  geom_boxplot()

# Linear Model
# Extract first two digits of age category for numeric age proxy
data_adults_lm <- data_adults |> 
  mutate(age = str_extract(age_cat, '^\\d{2}') |> as.numeric())  

my_linear_model <- lm(formula = "time ~ age + gender + prev_runs", data = data_adults_lm) 
cat("\n--- Linear Model Summary ---")
summary(my_linear_model)
```

### Python

```{python}
#| label: spss-task-py
#| warning: false
#| fig-width: 10
#| fig-height: 6
#| fig-align: center
#| fig-cap: "Various Outputs from SPSS Task (Python)"

import polars as pl
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
import statsmodels.formula.api as smf
import numpy as np

sns.set_theme(style="whitegrid")

path_to_file = "../00_data/RunningData.xlsx"
data = pl.from_pandas(pd.read_excel(path_to_file, sheet_name="Sheet1"))

# Rename columns
if len(data.columns) >= 5:
    data = data.rename({
        data.columns[0]: "position",
        data.columns[1]: "time",
        data.columns[2]: "age_cat",
        data.columns[3]: "gender",
        data.columns[4]: "prev_runs"
    })

print("---\n--- Head ---")
print(data.head())
print("\n--- Schema ---")
print(data.schema)
print("\n--- Summary ---")
print(data.describe())
print("\n--- Time Summary ---")
print(data["time"].describe())

# Subset adults
children_cats = ["10", "11-14", "15-17"]
data_adults = data.filter(~pl.col("age_cat").is_in(children_cats))

print("\n--- Adult Age Categories ---\n")
print(data_adults["age_cat"].unique())
print("\n--- Adult Time Summary ---")
print(data_adults["time"].describe())

# Analysis by gender
print("\n--- Analysis by Gender ---")
summary_gender = data_adults.group_by("gender").agg([
    pl.col("time").min().alias("min"),
    pl.col("time").mean().alias("mean"),
    pl.col("time").median().alias("median"),
    pl.col("time").max().alias("max")
])
print(summary_gender)

# Comparing distributions
g = sns.FacetGrid(data_adults.to_pandas(), row="gender", hue="gender", aspect=2, height=3)
g.map(sns.histplot, "time", edgecolor="white")
plt.show()

plt.figure(figsize=(10,6)) # Added figure size for consistency
sns.kdeplot(data=data_adults.to_pandas(), x="time", hue="gender")
plt.title("Density by Gender")
plt.show()

plt.figure(figsize=(10,6)) # Added figure size for consistency
sns.boxplot(data=data_adults.to_pandas(), x="time", hue="gender")
plt.title("Boxplot by Gender")
plt.show()

plt.figure(figsize=(10,6)) # Added figure size for consistency
sns.violinplot(data=data_adults.to_pandas(), x="time", y="gender", hue="gender")
plt.title("Violin Plot by Gender")
plt.show()


## Statistical tests
# Extracting the data
times_female_adults = data_adults.filter(pl.col("gender") == "F")["time"]
times_male_adults = data_adults.filter(pl.col("gender") == "M")["time"]

print("\n--- Female Times (Head) ---")
print(times_female_adults.head())
print("\n--- Male Times (Head) ---")
print(times_male_adults.head())

t_stat, p_val = stats.ttest_ind(times_male_adults, times_female_adults)
print(f"\n--- T-Test Results ---\nt-statistic: {t_stat}\np-value: {p_val}")

# Previous runs vs times
plt.figure(figsize=(10,6)) # Added figure size for consistency
sns.regplot(data=data_adults.to_pandas(), x="prev_runs", y="time")
plt.title("Time vs Previous Runs")
plt.show()

plt.figure(figsize=(10,6)) # Added figure size for consistency
sns.lmplot(data=data_adults.to_pandas(), x="prev_runs", y="time", hue="gender")
plt.title("Time vs Previous Runs by Gender")
plt.show()

# Correlation
corr, p_corr = stats.pearsonr(data_adults["time"], data_adults["prev_runs"])
print(f"\n--- Correlation Test ---\ncorrelation: {corr}\np-value: {p_corr}")

# Finding the median of prev runs
median_prev_runs = data_adults["prev_runs"].median()
print(f"\nMedian Previous Runs: {median_prev_runs}")

data_adults_pr_gr = data_adults.with_columns(
    (pl.col("prev_runs") >= median_prev_runs).alias("pr_gr")
)

print("\n--- Data with pr_gr group ---")
print(data_adults_pr_gr.select(["prev_runs", "pr_gr"]).head())

# a quick visual check
plt.figure(figsize=(10,6))
sns.histplot(data=data_adults_pr_gr.to_pandas(), x="prev_runs", hue="pr_gr", multiple="stack")
plt.title("Previous Runs Split")
plt.show()

# Comparing times
plt.figure(figsize=(10,6))
sns.boxplot(data=data_adults_pr_gr.to_pandas(), x="time", hue="pr_gr")
plt.title("Time by Previous Runs Group")
plt.show()

# Linear Model
data_adults_lm = data_adults.with_columns(
    pl.col("age_cat").str.extract(r"^(\d{2})", 1).cast(pl.Float64).alias("age")
)

model = smf.ols(formula="time ~ age + gender + prev_runs", data=data_adults_lm.to_pandas())
results = model.fit()
print("\n--- Linear Model Summary ---\n")
print(results.summary())
```
:::